<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RunSpec——一个跑步app设计]]></title>
    <url>%2Fblog%2F2021%2F06%2F23%2FRunSpec%E2%80%94%E2%80%94%E4%B8%80%E4%B8%AA%E8%B7%91%E6%AD%A5app%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[RunSpec——一个基于Kotlin前端，Kafka+Spark+MongoDB后台的跑步app设计 点击项目地址 本文主要记录了一个跑步app的设计过程，该项目是一个课余项目，主要是我为了加深对分布式应用架构的理解而写的。项目主体用Kotlin写前端安卓，前端安卓会读取用户安卓手机传感器中的数据并且传递到后台，后台的Kafka作跑步者数据的消息队列用以解耦与缓冲，再以Spark用以数据分析和存储到MongoDB中。由于笔者水平和时间有限，部分功能还在学习实践探索中。以下将对各个模块进行介绍。 adviser - 根据OpenWeather API的跑步建议的模块该模块是是一个极简的springboot项目，主要功能是根据当前经纬度调用OpenWeather API找到当前天气并且提供一个API。根据该API得到的天气可以为跑者在开跑前提供一些建议。 android - 安卓客户端Kotlin客户端，主要有三个界面。Home页面显示了用户的经纬度，天气情况，Top 5的跑步点（预设的POI，即point of interest，每当有用户经过POI，就会增加热度，对这个热度进行排序，选取前五个）。Dashboard页面展示了步数、跑步距离、跑步用时、经过的地方。Setting页面用来debug。 producer - 接收app数据并且转交给Kafka队列的模块由于目标是庞大的用户群体产生的实时跑步数据，因此使用Kafka来作解耦与缓冲的中间件。前端采集到数据后，发布这些数据给producer模块的Kafka broker再由processor模块消费。同时producer模块利用reslet建立了一些REST API来返回该用户历史跑过的POI，Top5的POI，和用户当前跑过的POI。 processor - 用Spark对实时数据进行分析并存储的模块订阅了Kafka broker的processor模块将对用户实时的跑步数据进行一个分析和存储。这里使用Spark来进行分布式处理较为妥当。首先Spark对mongoDB有原生操作的的connector，处理起来较为便捷。此处由于缺乏对相关例子的研究，并没有用到这个connector。而是简单地用insertOne逐条存储到MongoDB的runnerData表中。当然，对于预设的POI进行了广播，用以在不同的executor上处理数据流时可以由多个task共享一个POI，进行更快速的计算。同时，计算POI和用户经纬度的距离，若小于阈值，再判断是否已有同一用户id，同一tripId经过该点的记录，否则该POI热度加一。将这个count存入数据库表runnerPOIData中。 statisticsboard - POI跑步数据显示面板主要是一个springboot项目。它可以在localhost:8081可视化POI的热度，也可以检测经过POI的用户的记录表。数据每5秒通过stomp websocket推送到面版，再由leaflet.js在页面左边进行渲染可视化。页面右侧是一个表格，记录了trip Id，跑者Id，POI Id，距离与时间。]]></content>
  </entry>
  <entry>
    <title><![CDATA[DDIA 数据密集型应用笔记（I)]]></title>
    <url>%2Fblog%2F2021%2F06%2F02%2FDDIA%20%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Design Data-intensive applications (I) – 数据系统基础 可靠，可扩展，可维护的应用系统一个常见的应用系统应包括以下模块：数据库、高速索引（memcache，redis）、索引（ES)、流式处理（异步）、批处理（定期处理大量累计数据）。 API客户端请求进来，应首先检测数据缓存(redis)是否命中，命中就从内存读请求，否则更新数据库-&gt;数据库应数据变化更新缓存。同时更新数据库-&gt;更新索引，应用代码就可以进行全文索引(ES)查询。另外，对于异步任务可以交予消息队列(kafka)慢慢处理。 对于大多应用系统应考虑三个问题：可靠性(Reliability),可扩展性(Scalability),可维护性(Maintainability)。 可靠性： 硬件故障硬件冗余：磁盘RAID, 服务器双电源，热插拔CPU 软件错误特定值（闰秒）导致应用程序挂起，级联故障 人为失误抽象层，API以及管理界面。测试边界条件（property based testing)，自动化测试。滚动发布新代码，快速恢复机制。监控性能指标和错误率。 可扩展性 twitter案例：问题：当一个人tweet后，当follower查看自己的timeline时，需要联表查询，效率很低：1234SELECT tweets.*, users.* FROM tweets JOIN users ON tweets.sender_id = users.id JOIN follows ON follows.followee_id =users.id WHERE follows.follower_id = current_user 可以改进的一点是当一个人tweet时就fan-out到所有follower的timeline。虽然牺牲了这个人发布tweet的时间，但是所有follower查看timeline的速度都提升了。 当然如果这个人有很多的follower，就会导致发布时间太长，也不行，所以要混着用。 另外在批处理系统Hadoop中，throughput吞吐量（每秒可处理的记录条数，或者在某指定数据集上运行作业所需的总时间）很重要，而在线系统更关注响应时间。响应时间使用平均值并不好，因为可能出现极端值（上下文切换、进程调度、网络丢包、TCP重传、垃圾回收暂停、缺页中断、磁盘I/O），所以可以使用百分数（percentiles)，中位数。amazon使用99.9百分位数作为响应时间的标准，即1000个请求中有一个无需到达最小响应时间。 如何应对负载增加？垂直扩展vertical scaling（机器升级），水平扩展（负载分布到多个小机器）。有些系统具有弹性，可以自动检测负载增加然后分配更多计算资源。水平扩展会大大提升复杂性。 可维护性监控、自动化、标准工具集成（jenkins,Teamcity,K8s,JIRA,GitHub Action) 敏捷开发，TDD， 重构 数据模型与查询语言三种数据模型：关系模型、文档模型、图模型。 关系模型最知名的数据模型SQL，基于1970年提出的关系模型。数据被组织成关系，在SQL中称为表(table)，其中每个关系都是元组（tuples）的无序集合（SQL中的行）。 第一范式（1NF）强调的是列的原子性，表示列不能够分成其它几列。举例：联系人建表，电话要分成家庭电话和个人电话。第二范式（2NF），表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分，不符合 2NF 的设计容易产生冗余数据。举例【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName）= 【OrderDetail】（OrderID，ProductID，Discount，Quantity）+ Product】（ProductID，UnitPrice，ProductName）。第三范式（3NF），任何非主属性不依赖于其它非主属性。【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID），符合第二范式，但Custom也依赖于CustomID。应拆分出来参考：https://blog.csdn.net/Dream_angel_Z/article/details/45175621 关系数据库的核心在于商业数据处理，用例分为事务处理（银行交易，订票，仓库库存）和批处理（客户发票，工资单，报告）。 NoSQL超大数据集或超高写入吞吐量，关系模型不能很好地支持一些特定的查询操作。开源。 ORM对象关系映射框架有ActiveRecord和Hibernate，降低了应用层对象与传统关系模型之间转换的难度。面向文档数据库MongoDB, RethinkDB, CouchDB, Espresso。MongoDB数据库通过JSON模型将树形结构显示化。 MapReduce 查询MapReduce是一种编程模型,用于在许多机器上批最处理海量数据。一些 NoSQL 存储系统（例如MongoDB和CouchDB) 支持有限的MapReduce方式在大量文档上执行只读查询。举例： 在PostgreSQL中，统计每个月看到了多少鲨鱼，可以这样查询:12345SELECT date_trunc('month', observation_timestamp) AS observation_month, sum(num_animals) AS total_animals FROM observations WHERE family='Sharks' GROUP BY observation_month; 而在MongoDB中MapReduce功能可以这样实现目的：1234567891011121314db.observations.mapReduce( function map() &#123; var year = this.observationTimestamp.getFullYear(); var month = this.observationTimestamp.getMonth() + 1; emit(year + "-" + month, this.numAnimals); &#125;, function reduce(key, values)&#123; return Array.sum(values); &#125; &#123; query: &#123;family: "Sharks"&#125;, out: "monthlySharkReport" &#125;); 一个文档：123456&#123; observationTimestamp: Data.parse(&quot;Mon, 25 Dec 2020 12:11:11 GMT&quot;), family: &quot;Sharks&quot;, species: &quot;xxx&quot;, numAnimals: 3&#125; 对于每个匹配查询的文档，都会调用一次js的map函数，设为文档对象。 map函数emit一个kv对，key如”2021-06”，value代表观察的动物数量 对于相同的key，利用reduce按key分组，reduce将特定月份所有观察到的动物数量相加 写入monthlySharkReport集合中 map和reduce 函数对于可执行的操作有所限制。 它们必须是纯函数， 这意味着只能使用传递进去的数据作为输入， 而不能执行额外的数据库查询， 也不能有任何副作用。这样使得数据库能在任何位置，以任何顺序来运行函数，并在失败时重新运行这些函数。 MongoDB 2.2 增加了聚合管道查询 12345678910db.observations.aggregate([ &#123; $match: &#123;family: &quot;Sharks&quot;&#125;&#125;, &#123; $group: &#123; _id: &#123; year: &#123; $year: &quot;$observationTimestamp&quot; &#125;, month: &#123; $month: &quot;$observationTimestamp&quot; &#125; &#125;, totalAnimals: &#123; $sum: &quot;$numAnimals&quot; &#125; &#125;&#125;]); 图状数据模型属性图 每个顶点包括 唯一的标识符 出边的集合 入边的集合 属性的集合（键值对） 每个边包括 唯一的标识符 边开始的顶点 边结束的顶点 描述两个顶点间关系的label 属性的集合（键值对） 123456789101112131415CREATE TABLE vertices ( vertex_id integer PRIMARY KEY, properties json);CREATE TABLE edges ( edge_id integer PRIMARY KEY, tail_vertex integer REFERENCES vertices (vertex_id), head_vertex integer REFERENCES vertices (vertex_id), label text, properties json);CREATE INDEX edges_tails ON edges (tail_vertex);CREATE INDEX edges_heads ON edges (head_vertex); 123&lt;字段名A&gt; REFERENCES &lt;表名T&gt; &lt;字段名B&gt; -- 表示字段A存在，T表中必须存在相同的值字段BCREATE INDEX &lt;索引名&gt; ON edges (tail_vertex); -- 建立索引 数据存储与检索总体来说存储引擎分为两大类，OLTP（针对事务处理）的架构和OLAP（针对分析型）。OLTP系统面向最终用户，可能收到大量请求。为了处理负载，应用程序在每个查询中只涉及少量记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据，磁盘寻道时间是瓶颈。OLAP又业务分析师使用，处理的查询请求数目远低于OLTP系统，但每条查询需要在短时间扫描数百万记录。磁盘带宽（而不是寻道时间）是瓶颈，面向列的存储对于这种工作负载比较流行。 磁盘寻道时间：是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3-15ms。来源 磁盘带宽：正相关影响吞吐量（单位时间可以成功传输的数据数量）。 OLTP方面，有两个主要流派的存储引擎家族：日志结构的存储引擎（BitCask, SSTables, LSM-tree, LevelDB, Cassandra, HBase, Lucene）和面向页的存储引擎(B Tree，用于MongoDB, B+树用于MySQL)。 数据结构一个简易的database，实现了get和set： 12345678#!/bin/bashdb_set()&#123; echo "$1, $2" &gt;&gt; database&#125;db_get()&#123; grep "^$1," database | sed -e "s/^$1,//" | tail -n 1 &#125; 缺点：日志文件存储Key-Value存储对需要从头到尾扫描整个数据库文件来查找键的出现位置。 因此，加速读查询，索引是必要的。但是并不是索引越多越好，因为每个索引都会减慢写速度。 哈希索引 哈希索引基于哈希表。哈希表是一种查找算法，希望能尽量做到不经过任何比较，通过一次存取就能得到所查找的数据元素。因而必须要有一个确定的映射：数据的关键字key&lt;=&gt;数据元素位置。这种映射关系称为散列函数h(key)。最普通的散列函数：除留余数法h(key) = key MOD p, p&lt;=m。哈希冲突（不同key经由哈希函数生成的值相同）通常用拉链法解决。 为何不直接用哈希表来直接索引数据？哈希表存储了映射：键&lt;=&gt;数据文件的字节偏移量。查找某个key时，使用hash map找到文件中的偏移量，即存储位置，再读取其value。这就是Bitcask的做法。 Bitcask适合键的值频繁更新的场景。例如key是某个视频的url，value是播放的次数。有很多写操作，但没有很多key，也就是需要所有key都能保存在内存中。注意，这里key-value是追加式（日志的机制），那么怎样才能避免用尽磁盘空间呢？就是把具有相同key的记录压缩，只保留每个键最近的更新。这种实现方式是将日志分解成一定大小的段，当文件达到一定大小就关闭它并后续写入到新的段文件中。多个段也可以合并压缩，合并过程中，写请求还是在旧段上，但是合并后，写请求切换到新的合并后的段。每个段都有自己的内存哈希表，为了找到键的值，从最新的段开始依次检查。 追加式的日志看起来浪费空间，为什么不原地更新？ 追加和分段合并是“顺序写”，比随机写入快很多。 不必担心重写时发生崩溃。 避免碎片化问题 坏处：哈希表必须全部放入内存，有大量键就gg，（注意value很占空间没有问题，因为哈希表只是key&lt;=&gt;存储位置）。很难在磁盘上维护哈希表。区间查询效率不高，只能逐个查找每个键。 SSTables和LSM-TreeSSTable（Sorted String Table)在每个存储段都是一组key-value序列的日志结构的基础上，要求kv对的顺序按键排序。利用B树可以在磁盘上维护排序结构，而利用红黑树或AVL树可以在内存中排序。 SSTable优点： 合并段可以并发读取多个输入段文件，比较每个文件第一个键，把最小的键拷贝到输出文件，重复这个过程。如果重复键出现在多个输入段，保留最新段的值，丢弃旧段的值。 查找特定键时，不再需要在内存中保存所有键的索引。比如查找handwork，知道handbag和handsome就知道要找的offset在中间。 读写规则： 写入时，添加到内存中的平衡树数据结构中，这个内存中的树被称为内存表（memtable） 内存表大于某个threshold（通常几MB)时，将其作为SSTable写入磁盘。由于树已经维护了按键排序的kv，写磁盘比较高效。 处理读请求，先内存表，再最新磁盘段，再次新磁盘段。 后台周期性合并压缩 问题：数据库崩溃，内存表丢失。解决：磁盘上保留日志，每个写入追加到日志，可以乱序，崩溃后恢复内存表。当内存表写入SSTable写入磁盘，相应日志可以丢弃。 从SSTable到LSM-Tree以上算法是LevelDB和RocksDB使用的。类似还被用于Cassandra和HBase，这两个引擎都收到Google Bigtable论文的启发（SSTable和内存表memtable）。 Log-Structured Merge-Tree。基千合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。 Lucene是Elasticsearch和Solr等全文搜索系统使用的索引引擎。键是单词，值是保护该单词的文档ID的列表（倒排表）。在Lucene中这个映射保存在类SSTable的排序文件中，这些文件可以根据需要在后台合并。 优化：查找不存在的键，先SSTable，再最新磁盘段，再次新磁盘段……使用布隆过滤器（不存在某个键，很快告诉你结果）。大小分级（HBase）和分层压缩（levelDB），Cassandra支持这两种压缩。前者让较小较新的SSTables连续合并到旧和较大的SSTables。后者让键的范围分裂成多个更小的SSTables，旧数据被移到单独的“层级”，这样压缩可以逐步进行并节省磁盘空间。 LSM-tree的基本思想是保存在后台合并的一系列SSTable。数据按排序存储，可区间查询，不用存全部索引，磁盘顺序写入，高吞吐量。 B-TreesB-tree将数据库分解成固定大小的块或页,传统上大小为4 KB。页是内部读／写的最小单元。 这种设计更接近底层硬件， 因为磁盘也是以固定大小的块排列。某一页被指定为B-tree的根；每当查找索引中的一个键时，总是从这里开始。。 该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键， 相邻引用之间的键可以指示这些范围之间的边界。 一个页面引用另一个页面，引用指向磁盘地址而非内存。 B-tree中一个页所包含的子页引用数觉称为分支因子（branching factor)。 注意插入后可能的分裂过程，子页满了，分裂成两个half-full的页，父页也需要更新以包含分裂之后的新的键范围。该算法确保树保持平衡，具有n个键的B-tree总是具有O(logn)的深度。不需要非常深的页面层次就可以找到所需的页。分支因子为500的4KB页的四级树可以存储高达256 TB。计算：1500^4 * 4 * 1024 / (1e12) = 256 B树可靠性B-Tree的写是覆盖磁盘上的旧页，这与日志结构索引（LSM-Tree）不同，因为后者只追加不修改。B树的覆盖不会改变页的磁盘存储位置。被覆盖时引用的引用不变。 分裂时，需要更新对两个新子页的引用，如果部分页写入后发生崩溃，最终会导致索引破坏，为了恢复，常见B-Tree的实现需要支持磁盘上额外的数据结构：预写日志（write-ahead log, WAL)。这是仅支持追加的，每个B-tree的修改必须先更新WAL然后再修改树本身的页。 B树并发控制：latches锁存器（轻量级的锁）。LSM更简单，因为它们在后台执行所有合并，而不会干扰前端的查询，并且会不时地用新段原子地替换旧段。 对比B树和LSM树LSM树： 写入更快，因为有较低的write-amplification写放大（在数据库内，由于一次数据库写入请求导致的多次磁盘写），部分缘由顺序方式写入紧凑的SSTable文件，而不必重写树中的多个页。（顺序写&gt;随机写） 读取慢，因为必须不同压缩阶段检测多个不同的数据结构和SSTable B树： 读取更快 每个键都恰好唯一对应索引的某个位置，LSM可能在不同段中有相同键的多个副本 其它索引结构二级索引使用CREATE INDEX命令。以便可以在每个表中找到属于同一个索引的所有行。 聚集索引：直接存储索引行，无额外跳转，MySQL的InnoDB的表的主键是聚集索引。非聚集索引：value可以是对其它地方存储的行的引用（具体位置称为堆文件），在有多个二级索引时，可以避免复制数据，实际数据仍保存在一个位置。 前者需要额外空间，加快了读取速度，后者反之。 事务处理与分析处理OLTP (online transaction processing) 在线事务处理。 OLAP (online analytic processing) 在线分析处理。 公司放弃使用OLTP系统用于分析目的，而是在单独的数据库上运行分析，这个单独的数据库被称为数据仓库（Data Warehousing）。 可以理解为，对于终端用户操作交互的是OLTP系统的数据库（电商网站-&gt;销售数据库，车辆路径规划-&gt;地理数据库）；而OLAP系统将这些数据库中的信息提取出来，进行数据转换和加载（Extract-Transform-Load，ETL）到数据仓库中，由商业分析员进行查询。 列式存储分析人们购买新鲜水果或糖果的倾向是否取决于一周中的某天1234567891011SELECT dim_date.weekday, dim_product.category, SUM(fact_sales.quantity) AS quantity_soldFROM fact_sales JOIN dim_date ON fact_sales.date_key = dim_date.date_key JOIN dim_product ON fact_sales.product_sk = dim_product.product_skWHERE dim_date.year = 2013 AND dim_product.category IN ('Fresh fruit', 'Candy')GROUP BY dim_date.weekdat, dim_product.category 想要高效执行这个查询，可以在fact_sales.date_key和fact_sales.product_sk上使用索引，告诉哪里找特定产品的所有销售。但这依然会从磁盘加载所有行（一行所有的一百多个属性）到内存，解析，再过滤不符合所需条件的行。在大多数OLTP数据库中，存储以面向行的方式布局，来自表的一行所有值彼此相邻存储。文档数据库的文档也被存储为一个连续的字节序列。 面向列存储，就不需要将一行中的所有值存储在一起，而是将每列的索引值存储在一起。只加载相关列的所有行，再过滤不符合所需条件的行，就快很多。 面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行。 因此，如果需要重新组装整行，可以从每个单独的列文件中获取第23个条目，并将它们放在一起构成表的第23行。 列压缩 常见技术：bitmap encoding位图压缩，位图可以进行run-length encoding游程编码。具体见书上的例子。 12345WHERE product_sk IN (30, 68, 69);加载3个bitmaps，然后按位或。WHERE product_sk = 31 AND store_sk = 3:加载两个bitmaps然后按位与。（思考为什么这个也行） 列存储的排序 排序可以区间查询，也可以进一步压缩列，压缩游程（run-length encoding）。 列存储的写操作 插入一行后，如果想要像B树一样原地更新不太可能，因为必须重写所有列文件，一致地更新所有列。因此要使用LSM-tree，首先进入内存存储区，再添加到已排序的结构中，再写入磁盘。这个过程与面向行还是面向列无关。当累积了足够多的写入时，将与磁盘上的列文件合并，并批量写入新文件。这是Vertica采取的方式。]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubiquitous computing and IoT 普适计算与IoT]]></title>
    <url>%2Fblog%2F2021%2F04%2F13%2Fubiquitous-computing-%E6%99%AE%E9%80%82%E8%AE%A1%E7%AE%97%E7%BB%BC%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[ubiquitous computing &amp; IoT With the booming development of 5G technology and the Internet, peopleare witnessing the era of the intelligent world that everything is connected.Internet of things (IoT) and Ubiquitous computing (UbiComp) are two hottopics under such circumstances. The article [1] written by R.M.C. Andrade etal. is a good material to help readers learn about the relevant concepts of IoTand ubiquitous computing and provide examples of real-world applications andmetrics to measure the characteristics of IoT and UbiComp. This article reviewwill simply summarize the arguments of the article and offer my opinions on thepros and cons of this article. In the introduction of the article [1] written by R.M.C. Andrade et al, Ubiq-uitous Computing (UbiComp) is a concept occuring before the emergence of IoTand basically UbiComp is to let people use services and technologies withoutperceiving them. As they point out, UbiComp emphasizes on Human-Thinginteractions. IoT shares many commonalities with UbiComp such as Human-Thing interactions but on the other hand, IoT is at a more complex level be-cause it also takes Thing-Thing interactions into considerations. However, theyhold the argument that Human-Thing interactions are significantly impacted byThing-Thing interactions. Meanwhile, they raise the argument that the mea-sures that focus on the characteristics of UbiComp, can also be applied to IoT. To address these arguments, the authors, in the chapter of background, pro-vides further explanations on 5 general characteristics, namely context-awareness,mobility, transparency, attention and calmness of ubiquitous applications outof 27 essential quality characteristics identified in previous work of the authors[2]. To support the rationality for measuring of the characteristics, the authorsrefer to their previous studies, in which they provide detailed calculating func-tions for each characteristic. Simultaneously, the authors point out that IoTis composed of six elementary building blocks, namely identification, sensing,communication, computation, services and semantics. These six elements aretightly related to Thing-Thing interaction, which also allows broader communi-cation over Internet, and is not like Machine-To-Machine (M2M) which simplysupports connection on local wired or wireless networks. By analyzing these sixelements the authors insist that two UbiComp features, context awareness andadaptability can be mapped to IoT domain as measures of the characteristicsof IoT, which respectively capture the context information to serve users andmake changes based on the information. Another important feature presented is the spontaneous interaction, which is related to adapted behaviors of the IoTdevices in or out of the environment. This article then provides some experiments and evaluates on their results. To summarize, three UbiComp applications have been made which have threemain functionalities to block video based on battery level (GREat Tour), to mutedevices when the user is in an office and it is the time for the meeting specified onthe user’s agenda (GREatMute), to print documents at the nearest printer forusers (GREatPrint). Meanwhile, two IoT applications are made to respectivelyenable users to control the air conditioners and lamp manually or automaticallyby motions (Automa GREat) and report the presence of people in a particularroom (GREat Room). A comparison is made on the three UbiComp applicationsand the two IoT applications regarding to six more detailed measures mentionedbefore (adaptability, context-awareness etc.). The article insists that measurescome from UbiComp can be applied to IoT applications. I would argue that the applications given are indeed typical ones in relevantareas. It is also reasonable to measure on the characteristics based on the metricsbeforehand. However, the evaluation result cannot necessarily indicate that themeasures that come from UbiComp can be fully applied to IoT applications. Itis not persuasive that GREatRoom is an IoT application rather than a UbiCompapplication, since it also provide services without people manually or externallyperceive or manipulate it (UbiComp). In that case, if we classify GREarRoomas a UbiComp application, the result of AutomaGREat cannot support theargument because two measures of AutomaGREat are zero percentage and itwould be hard to convince people that the two measures really matters to othertypical IoT applications. One solution I would suggest to resolve the problem isto provide another indeed typical IoT application that has a non-zero adaptationdegree and correctness. In the final discussion, the article lists questions and answers to them, includ-ing firstly the commonalities of UbiComp and IoT applications, secondly the in-teraction problems such as synchrony of IoT data, lack of conflicts handling, de-lay of communication, thirdly the characteristics and measures of Thing-Thinginteraction such as synchronicity, responsiveness, reliability, battery, context-Awareness, interoperability and difficulty of installation, fourthly the majorchallenges to the interaction in IoT such as interoperability, consistency of theinteractions, verification of interest conflicts, and evaluation. To sum up, the article serves as a good material to let readers learn aboutthe concepts of UbiComp and IoT, the commonalities and differences betweenthem, the typical applications and how the charateristics can be measured as acriterion for practitioners. The article also point out the challenges for buildingUbiComp and IoT applications, and motivate researchers to think of adaptingthier UbiComp applications to IoT uses in future study. References[1] R. M. Andrade, R. M. Carvalho, I. L. de Ara ́ujo, K. M. Oliveira, and M. E.Maia, “What changes from ubiquitous computing to internet of things in in-teraction evaluation?” inInternational Conference on Distributed, Ambient,and Pervasive Interactions. Springer, 2017, pp. 3–21. [2] R. M. Carvalho, R. M. de Castro Andrade, K. M. de Oliveira,I. de Sousa Santos, and C. I. M. Bezerra, “Quality characteristics and mea-sures for human–computer interaction evaluation in ubiquitous systems,”Software Quality Journal, vol. 25, no. 3, pp. 743–795, 2017.]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式系统原理]]></title>
    <url>%2Fblog%2F2021%2F04%2F02%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[分布式系统原理 本文基于ID2203 Distributed Systems, Advanced Course课程，对整个分布式领域的问题进行一个总结。课程参考了Introduction to Reliable Distributed Programming, Introduction to Distributed Algorithms 等书籍。前者更偏向代码实现，书中的伪代码清晰易懂，有兴趣的读者可以买一本看看。 待更。]]></content>
  </entry>
  <entry>
    <title><![CDATA[电影推荐系统设计]]></title>
    <url>%2Fblog%2F2021%2F04%2F02%2F%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[电影推荐系统设计 本文出发点是总结市面上比较流行的电影推荐系统后端设计的整个流程，包括阐释Kafka/Redis/Spark/ES等工具的作用、在哪里用、怎么去用这些问题，并且加入自己的一些思考。 项目地址 项目管理MavenApache Maven是一个软件项目管理和理解工具，它基于项目对象模型（POM）的概念，可以用以管理项目的构建，报告与文档。 本项目是一个Maven项目，采用父子项目的结构形式。Maven项目中子项目就是一个Maven module，可以通过右键-&gt;New-&gt;Module-&gt;Maven然后设置即可创建。pom文件中可以设置父子项目的信息。在主目录MovieRecommenderSystem下，我们创建一个Maven module名为recommender，再在recommender下建立五个Maven module名为DataLoader（数据加载），StatisticsRecommender(统计推荐），OfflineRecommender（离线推荐），ContentRecommender(基于内容的推荐)，StreamingRecommender（流式推荐）。 同时，在pom文件中，也可以引入相关的jar包依赖。比如spark-core, spark-sql, spark streaming，mongodb的驱动等等。 数据加载DataLoaderDataLoader主要处理把csv文件的数据集加载到数据库MongoDB中。由于我们现有的数据集是三个csv文件，分布存储了电影信息，评分信息和标签信息。为此我们创建了三个case class，Movie、Rating、Tag，其中参数与csv的headers一一对应。Movie有电影id（mid），名字，描述，时长，发行日期，拍摄日期，语言，派别，演员，导演十个参数；Rating有用户id（uid），电影id，电影评分score，评论时间戳timestamp四个参数；Tag有用户id，电影id，tag名，时间戳四个参数。 由于数据集很大，使用Spark来读取到MongoDB中是一个好的选择，否则数据全都存在内存中就崩了。Spark可以尽可能地使用本地的线程分布式地读取数据并存储在MongoDB中。在SparkContext指定数据的路径，并且对csv文件进行一些split和toDF操作得到一个DataFrame，再对DataFrame进行write-&gt;option-&gt;mode-&gt;format-&gt;save就可以存储MongoDB即可。其中option带有mongo的uri和表名，mode表示存储的形式（可以是overwrite）。此外，还需要对每张表的mid，uid建立索引，指定descending或ascending。建立索引能大大加快查找数据的速度[reference]. 在这个模块中，我们使用了MongoDB作为数据库，Spark作为数据读写工具存储到MongoDB。当然，我们也可以把数据存储到ElasticSearch中，以供用户搜索。一般说来，对于读多写少的存储ES是可以替代MongoDB的[reference]。我们可以将这些固定的表写入ES，向用户提供更快的全文检索等搜索服务。 统计推荐StatisticsRecommenderStatisticsRecommender统计推荐和OfflineRecommender离线推荐都是使用Azkaban进行定时的触发执行的模块。本段主要介绍统计推荐模块。 统计推荐模块对上文DataLoader存储在mongo中的数据进行一个分析，从而得到一下四个推荐结果： 最热电影 一个电影的热度通常用点击量或者评论量来衡量。这里用spark sql统计排序Rating表中具有同一个电影id（mid）的数据的行数，返回一个dataframe，把它写入mongo的RateMoreMovies表。1select mid, count(mid) as count from ratings group by mid order by count desc 最近的最热电影 与上面类似，但是排序还要优先考虑评论时间（timestamp）首先注册一个spark udf名为changeDate，对原来表中的timestamp转换成yyyyMM的形式, 得到ratingOfMonth表1select mid, score, changeDate(timestamp) as yearmonth from ratings 再对ratingOfMonth表每个yearmonth，统计每个电影出现个数，对yearmonth、个数排序。1select mid, count(mid) as count, yearmonth from ratingOfMonth group by yearmonth, mid order by yearmonth desc, count desc 返回结果写入mongo的RateMoreRecentlyMovies表。 Top电影 Top电影考虑的不是评论数而是评分的高低，也就是由平均评分进行一个排序1select mid, avg(score) as avg from ratings group by mid order by avg desc 当然有时我们也可以确保评分个数大于某个数量，因为如果电影只有一条五星评分不足以断定它是Top电影。只需要加上having count(mid)&gt;阈值即可 每个类别的Top电影 之前已经计算了Top电影得到了一个名为averageMoviesDF的dataframe，将其与movieDF通过mid进行inner join操作得到一个movieWithScore（含有movie整体信息，包括我们需要的genre信息，以及avg score）。 考虑到有些电影的派别字段有多个类别genres（用竖线分割），我们就应该先对一个里面有所有的genre的list，和movieWithScore做一个笛卡尔积，然后做一个filter，对每个genre和movieRow（movieWithScore的一行），过滤掉movieRow的genres字段中不含有genre的记录。然后再将整个数据集的数据量减小，只留下必要的记录，生成RDD[genre, Iter[mid, avg score]]，再对genre做groupBy，sortWith平均分，即可得到最后的每个类别的Top电影的集合，将它保存在mongo里。 离线推荐OfflineRecommenderStatisticsRecommender统计推荐和OfflineRecommender离线推荐都是使用Azkaban进行定时的触发执行的模块。本段主要介绍离线推荐模块。 统计推荐使用sql对于显性数据进行分析，而本模块使用了spark ML来做一个基于隐语义模型的协同过滤（CF）的推荐。实际上CF这一块主要分为itemCF和userCF，前者就是两个相似的电影，如果user看了一个那么另一个就可以被推荐；而后者就是两个相似的user，如果一个user看了一个movie那么这个movie也可以被推荐给另一个user。这里由于我们没有考虑user标签，所以采用的是itemCF的方式来进行离线推荐。 那么怎么断定两个电影相似？首先要找到features。给定训练集（user,product,rating)的元组和超参数rank、iterations、lambda，spark ML的ALS算法可以让我们训练出一个model。这个model可以得到一些item的features（productFeatures），我们也可以用这个model直接predict出每个user对每个product的rating。这个有什么用呢？因为原本user不可能对所有movie都评分，user对movie的评分矩阵必然是稀疏的[reference]，但是为了得到每个user对每个movie的评分，ALS算法通过一定规律找到了features，填补了原来没有评分的地方。这样我们很轻易就可以进行一个排序然后得到一个用户的电影推荐列表了。最后存入了mongo的userRecs表。 另外，相似电影也可以通过features信息得到。两个电影都有等长的features列，进行一个余弦相似度的计算（阈值&gt;0.6）就可以得到相似电影矩阵。由于短时间相似电影矩阵都不会发生变化，可以存入mongo的MovieRecs表为实时推荐服务。 实施推荐StreamingRecommenderStreamingRecommender提供了流式推荐服务，是针对用户评分行为的实时推荐模块。简单说来，就是当用户 u 对电影 p 进行了评分，将触发一次对 u 的推荐结果的更新。为此，我们先创建一个kafka流，用以实时接收评分message（UID|MID|SCORE|TIMESTAMP）。并且同时定义stream的LocationStrategies（分区分配方式）和ConsumerStrategies（消费者接收什么topics）[reference]，每当用户评分后，Flume-ng会采集到日志并且推送到kafkaStream，算法会对每个RDD的uid和mid 根据uid找到redis中存储的最近K次电影评分，得到一个Array[(Int, Double)]，即(mid, score)的array 根据mid找到mongoDB中存储的N个最相似的电影（mongoDB中已有通过OfflineRecommender模块ALS算法计算出的相似电影表），并且过滤掉已经看过的电影），得到一个Array[Int]，即候选电影的array 融合步骤1的用户最近看过的K次电影和步骤2中找到的每个候选电影，计算出得分并排序成一个推荐列表。得分需要参考相似度，因为我们希望推荐和用户最近看过相关的电影；但得分也同时需要参考评分，因为可能虽然候选电影相似，但是评分爆低的电影我们也不希望推荐给用户； 保存Array[(Int,Double)]，也即mid和上面计算的得分score的元组数组到MongoDB。 其中有用到redis(jedis), mongoDB, spark, kafka。步骤1使用redis存储最近K次电影评分，好处是因为redis的高速缓存，由于redis是一个内存数据存储，它不能存储非常大的数据，通常数据库内存满了就会通过LRU等淘汰策略，这对读写“最近K次的电影评分”来说，是相当符合的，步骤2使用mongoDB存储相似电影矩阵是因为，mongoDB是基于磁盘的数据存储，无需担心空间的限制，因此存在mongoDB中会更好。使用kafka是因为kafka是一个基于分布式日志的高吞吐、低延迟的发布/订阅消息队列，考虑到同时有一万个用户的电影评分数据（UID|MID|SCORE|TIMESTAMP)需要处理，而这些处理很花费时间，利用kafka做一个中介来暂时存储这些数据，而不是先存入mongoDB然后再读出来计算，会大大增加处理速度，减少数据库压力。 总的说来，当用户评分后，评分数据会通过kafka然后通过我们的实时推荐算法进行处理。当中需要用到redis存储的最近K次评分与mongo存储的相似电影表来计算score并排序得到推荐列表。然后把这个推荐列表存储到mongo里面，之后我们渲染到前端就可以看到推荐结果了。 内容推荐ContentRecommenderContentRecommender是基于内容的推荐。考虑我们通过DataLoader模块存储了Movie表。我们可以假设关键属性是类型genres，描述，演员，导演。尤其是genres，我们可以用来进行冷启动的（首次注册时，询问用户他们喜欢的类型用以建立他们的用户个人资料）。我们可以简单地对类型应用one-hot编码，但通常不同的类型应具有不同的权重。例如，大多数战争电影都是动作电影，因此带有战争标签的电影应该更有价值。在这种情况下，我们可以使用tf-idf算法而不是ALS来解决问题。 在该系统中，tf-idf用于genres，并在MongoDB中生成一个名为ContentMovieRecs的表，并且该部分还可以与Streaming推荐器模块中实现的Kafka Streaming结合使用。 tf-idf是正相关与term frequency，负相关于inverse document frequency，它原来的意思是说，当一个词语出现在一个文档中越多（term frequency），它越有价值；但同时如果一个词语出现在多个文档中都很多（inverse document frequency），比如the，a，an这种，它越没有价值，即使tf很高也没有用。类比于我们的genres这个属性，可能一个用户看了许多动作片，但如果很多影片genre中都有动作片这个标签，动作片这个标签就没有那么有价值。利用spark ML中的HashingTF，IDF，Tokenizer可以找到电影tag（genre）的features，然后再计算余弦相似度就可以得到相似电影矩阵，提供给StreamingRecommender进行实时推荐了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Distributed Systems revision]]></title>
    <url>%2Fblog%2F2021%2F03%2F18%2FDistributed-Systems-revision%2F</url>
    <content type="text"><![CDATA[Distributed Systems revision IntroductionWhy study distributed systems? (2) Partial Failures Network (dropped msgs, partitions) Node failures Concurrency Nodes execute in parallel Msgs travel asynchronously Two Generals’ Problem Concensus? All correct nodes eventually decide Every node decides the same Only decide on proposed values Database Concurrent changes to same data Nodes should agree on changes Use a kind of concensus: atomic commit {commit, abort} Given Atomic Broadcast, can use it to solve concensus =&gt; consensus cannot be solved in asynchronous system if a single node may crash No bound on time to deliver a msg No bound on time to compute Clocks are not synchronized =&gt; consensus solvable in synchronous system with up to N-1 crashes Known bound on time to deliver a msg know bound on time to compute known lower and upper bounds in physical block drift rate Partially synchronous system with up to N/2 crashes Consensus and Atomic Broadcast solvable with failure detectors Byzantine algorithms tolerate up to 1/3 Byzantine processes Basic AbstractionDistributed algorithms are implemented as middleware between network(OS) and the application. 1) Network protocols aren’t enough TCP only offered for one-to-one communicationHow to group communication Abstractions in this courseReliable Broadcast – Causal order broadcast – Total order broadcast 2) N-N communication isn’t enough Need reliable high-level services Shared memoryConsensusAtomic commitRSM Reliable Distributed abstractionsex: reliable broadcast (ensure the msg sent to a all or one); atomic commit (reach the same decision on whether to commit or abort a transaction) Event-based Component ModelEvents(3) Msgs, Timers, Conditions Two types of eventsRequests (Inputs) Indications (Outputs) Stack of Components in a single process Example:Implements: JobHandler, intance jhupon event &lt;jh, Submit|job&gt; do process(job) trigger&lt;jh, Confirm|job&gt; How to specify a distributed service? (4) Interface (aka Contract, API) Requests Responses Correctness Properties Safety Liveness safety 有限时间内可以被违背= safty is false for an execution E if there exists a prefix such that all extensions are falseliveness 无限时间内才可以被达成= liveness is true for an execution E if for all prefixes there exists an extension that is true Model Assumptions on failure Assumptions on timing (amount of synchrony) failure types (4) crash-stop, omissions, crash-recovery, byzantine:Omission failure covers both (1) Send omission (Not send what has to be sent), (2) Receive omissionIn Crash recovery failures, a process is faulty in an execution if it crashes and never recovers or recovers infinitely often. (amnesia: the recovered nodes might not be able to restore all of state)In Byzantine failures, a process may behave arbitrarily: sending or updating its state as not specified by its algorithm, and behave maliciously (collude) Byzantine &gt; Crash-recovery &gt; Omission &gt; Crash Channel failure modes (5) Fair-Loss Links Channels delivers any message sent with non-zero probability (no network partitions) FL1. Fair-Loss: if m is sent inf often by pi to pj, and neither crash, then m is delivered infinitely often by pj FL2. Finite duplication FL3. No creation: No msg is delivered unless it was sent Stubborn Links Channels delivers any message sent infinitely many times SL1. Stubborn delivery: correct pi msg -&gt; pj, pj delivers infinitely SL2. No creation Perfect Links Channels that delivers any message sent exactly once PL1. Reliable Delivery: correct pi msg -&gt; pj, pj eventually deliver PL2. No duplication: deliver once PL3. No creation use stubborn links to implementkeep log of received msgs in Delivered FIFO Perfect linksFIFO. Ordered Delivery Logged Perfect Links Channels delivers any message into a receiver’s persistent store (msg log) Authenticated Perfect Links Channels delivers any message m sent from process p to process q, that guarantees the m is actually sent from p to q Timing: Clocks =&gt; Lower and upper bounds on clock rate-drift and clock skew with regarding to real timeCausal ordera -&gt; b(1) a occurs before b on the same process(2) if a is a send(m) and b deliver(m), then a -&gt; bCausal order is transitiveTwo events are concurrent if not a -&gt; b and not b -&gt; a Partial &amp; Total OrdersPartial -&gt; doesn’t order concurrent eventsTotal -&gt; any two distinct clock values are ordered (adding pid) Implementation Composed of other services Adheres to interface and satisfies correctness Has internal events Failure DetectorsDistributed algorithms are implemented as middleware between network(OS) and the application. 1) Network protocols aren’t enough TCP only offered for one-to-one communicationHow to group communication Abstractions in this courseReliable Broadcast – Causal order broadcast – Total order broadcast 2) N-N communication isn’t enough Need reliable high-level services Shared memoryConsensusAtomic commitRSM Reliable Distributed abstractionsex: reliable broadcast (ensure the msg sent to a all or one); atomic commit (reach the same decision on whether to commit or abort a transaction) Event-based Component ModelEvents(3) Msgs, Timers, Conditions Two types of eventsRequests (Inputs) Indications (Outputs) Stack of Components in a single process Example:Implements: JobHandler, intance jhupon event &lt;jh, Submit|job&gt; do process(job) trigger&lt;jh, Confirm|job&gt; How to specify a distributed service? (4) Interface (aka Contract, API) Requests Responses Correctness Properties Safety Liveness safety 有限时间内可以被违背= safty is false for an execution E if there exists a prefix such that all extensions are falseliveness 无限时间内才可以被达成= liveness is true for an execution E if for all prefixes there exists an extension that is true Model Assumptions on failure Assumptions on timing (amount of synchrony) failure types (4) crash-stop, omissions, crash-recovery, byzantine:Omission failure covers both (1) Send omission (Not send what has to be sent), (2) Receive omissionIn Crash recovery failures, a process is faulty in an execution if it crashes and never recovers or recovers infinitely often. (amnesia: the recovered nodes might not be able to restore all of state)In Byzantine failures, a process may behave arbitrarily: sending or updating its state as not specified by its algorithm, and behave maliciously (collude) Byzantine &gt; Crash-recovery &gt; Omission &gt; Crash Channel failure modes (5) Fair-Loss Links Channels delivers any message sent with non-zero probability (no network partitions) FL1. Fair-Loss: if m is sent inf often by pi to pj, and neither crash, then m is delivered infinitely often by pj FL2. Finite duplication FL3. No creation: No msg is delivered unless it was sent Stubborn Links Channels delivers any message sent infinitely many times SL1. Stubborn delivery: correct pi msg -&gt; pj, pj delivers infinitely SL2. No creation Perfect Links Channels that delivers any message sent exactly once PL1. Reliable Delivery: correct pi msg -&gt; pj, pj eventually deliver PL2. No duplication: deliver once PL3. No creation use stubborn links to implementkeep log of received msgs in Delivered FIFO Perfect linksFIFO. Ordered Delivery Logged Perfect Links Channels delivers any message into a receiver’s persistent store (msg log) Authenticated Perfect Links Channels delivers any message m sent from process p to process q, that guarantees the m is actually sent from p to q Timing: Clocks =&gt; Lower and upper bounds on clock rate-drift and clock skew with regarding to real timeCausal ordera -&gt; b(1) a occurs before b on the same process(2) if a is a send(m) and b deliver(m), then a -&gt; bCausal order is transitiveTwo events are concurrent if not a -&gt; b and not b -&gt; a Partial &amp; Total OrdersPartial -&gt; doesn’t order concurrent eventsTotal -&gt; any two distinct clock values are ordered (adding pid) Implementation Composed of other services Adheres to interface and satisfies correctness Has internal events Reliable BroadcastFail-stop &lt;=&gt; synchronous (P + PL_Link)Fail-silent &lt;=&gt; aynchronous (PL)Fail-noisy &lt;=&gt; partially synchronous (*P + PL)Fail-recovery &lt;=&gt; (stubborn links or a persistent logs) Quorums A set with at least floor(N/2) + 1 processesresilience f max number of faulty processes &lt; N/2 no deliver guarantees whether sender fails or not 5 reliable broadcast abstractionsBest-Effort: Guarantees reliability only if sender is correctReliable broadcast: Guarantees reliability independent of whether sender is correctUniform reliable broadcast: Also considers behavior of failed nodesFIFO reliable broadcast: Reliable broadcast with FIFO delivery orderCausal reliable broadcast: Reliable broadcast with causal delivery order Best-effort broadcast:If p_i is and broadcast then eventually all processes deliver; (Best effort validity) + No duplication + No creation Reliable broadcast: (Best-effort + Agreement)考虑了发送者fail但有correct的node deliver的情况，这种情况下也必须其它correct的node都deliver&lt;==&gt;If p_i is correct then eventually all correct processes deliver m. If p_i is faulty then either all correct processes eventually deliver m, or no correct process delivers m; Algo: Fail-Stop, Lazy Reliable BroadcastUse P Agreement: If a correct node delivers m, then every correct process delivers m Uniform Reliable broadcast:Reliable broadcast + Uniform Agreement (发送者fail，只要有node deliver，不管crash or correct，别的correctnode都deliver）If a process delivers message m, then every correct process delivers m (Uniform agreement, take “keeping uniform with faulty process which delivers m” into consideration) one time unit is the longest message delay in E Complexity of lazy reliable broadcastN processesBest case: O(N) msgsWorst case: O(N^2) msgsTime complexityBest case: 1 time unitWorst case: 2 time units Eager Reliable Broadcast In lazy rb, we only use completness of P, not related to correctnessQ: replace P with *P? A: replace P with diamond P will lead to:“Pk gets info that Pi has crashed” false (Pi do not crash at all, although Pk will eventually get that Pi is alive, it currently thinks Pk is crashed. So:Pk rebroadcast all msgs of Pi (it is unnecessary) only affect performance, not affect correctness For Uniform Eager Reliable BroadcastWe add a ack list; when all acks received, urb deliver. Uniform agreement need P. Majority-ACK Uniform RB &lt;==&gt;fail-silentResilience less than N/2 for fail-stop algorithmhas resilience = N - 1all acks weaker constraints on ACK less resilience tradeoff Causal BroadcastFor Chat applicationWe should maintain a causal (happen-before) order on the contextUniform broadcast does not remedy this.! Causal reliable broadcast solves this Causality of messageC1 (FIFO order) Some process pi broadcasts m1 before broadcasting m2C2 (Network order) Some process pi delivers m1 and later broadcasts m2C2 (transitivity) There is a message m’ such that m1 -&gt; m’ and m’ -&gt; m2 Causal BroadcastCB: If node pi delivers m1, then pi must have delivered every message causally preceding -&gt; m1 before m1 CB’: If pj delivers m1 and m2 (保证要deliver), and m1 -&gt; m2, then pj must deliver m1 before m2 满足CB’ 不满足CB的情况：图 实现在rb基础上，使用P做GCFail-Silent No waiting causal broadcast Each message m carries ordered list of causally preceding messages in past_m message size grows, uaw Perfect detector P to garbage collect old messages 实现在FIFO-rb上Fail-Silent Causal Broadcast Each msg carries a history, history is set of all causally preceding messages, and a vector timestamp Only deliver m once VCm ≤ VCiDo Not deliver if VCm &gt; VCi or VCm ≠ VCi Single-Source FIFO orderIntuitively: Msgs from same node delivered in order sentFor all msgs m1 and m2 and all pi and pj, if p i broadcasts m1 before m2, and if pj delivers m2, then pj delivers m1 before m2This formulation doesn’t require delivery of both msgs Total OrderIntuitively: Everyone delivers everything in exact same orderFor all messages m1 and m2 and all pi and pj,if both pi and pj deliver both messages, then they deliver them inthe same orderThis formulation doesn’t require delivery of both msgsEveryone delivers same order, maybe not send order! 如果不是single-source fifo必不是total order Hierarchy 图 Distributed Shared MemorywikiThe memory location which is concurrently accessed (read/write/CAS) is sometimes called a register. DSM interface (4)read invokation, read response, write invocation, write response Regular Register (1, N) Termination Each read and write of a correct node completes ValidityRead returns last value written if Not concurrent with another write and Not concurrent with a failed writeOtherwise may return last or concurrent “value” Read-One Write-All (1, N) algorithmread locally没有RTT，之后的算法都是read globallyP22 Postpone write responses to ensurethe writer does not return until it knows that the reader delivers the value that is broadcasted写有1个RTT2 communication steps (broadcast and Ack from all)O(N) messagesresilience: N-1然而却要Perfect Failure Detector，下面的就不用FD Majority voting (1,N) algorithmEach process stores the value of all registers=&gt; write(r, v)UPDATE PHASEts++(ts is a sequence number initialized to zero at the writer and incremented at each write)timestamp-value pair, tvp = (ts, v)send 一个update requestpj updates r = max(r, (ts, v)) and responds with ACKQUERY PHASEpi sends query, receives response (ts,v), picks max(ts, v) !Avoid old writes overiting new writewrite will be ignored if it has lower timestamp 2 communication steps (one round trip)O(N) messagesresilience: f &lt; floor(N/2) Atomic/Linearizability vs. Sequential Consistencysequential order vs. global time order看例子 Majority voting算法是regular register但是如何保证Atomic的？ (SWMR)Read-Impose Write Majority (1, N)P66 When reading, also do an update (if ts same, then just return) before responding读后写，写上一个写的值 (MWMR linerizable)Atomic Register Read-impose write-consult-majority (N, N)具有linearizability Before writing, read from majority to get last ts Do a query phase to get the latest timestamp before the update phase 为了synchronize ts Two concurrent writes with same ts? compare process identifierwrite operationquery + update phasewrite needs 2 tripsOne for the timestampOne for broadcast-ACK写前读，读上一个ts + 读后写，写上一个写的值read needs 2 round-tripsone for readone for impose if necessary (MWMR sequential consistent)==&gt;LTLogical Time algorithm (LT)(N,N) Seq ConsistentWrites in 1 RTT and reads in 2 RTTsTolerates f&lt;n/2 faulty processesLinearizability in logical time allows compositionality tvp = ((lt, i), v)((10,1),5) timestamp 10, pid 1,value 5 Livness(3)Wait-free (no deadlocks, no live-locks, no starvation)Lock-free/non-blocking (no deadlocks, no live locks, maybe starvation)Obstruction free/solo-termination (no deadlocks, maybe live-locks, maybe starvation) 总结Distributed Algorithms ===&gt;the weak model (regular register) SWMR (Single write multiple read) regular registers Bogus algo (did not work)Centralized(no failures)Read-One Write-All Algorithm (P)Majority Voting(No FD) ===&gt;the strong model(atomic register)atomic register SWMR linearizable registers read-impose idea MWMR linearizable registers read-impose write-consult MWMR sequentially consistent registers read-impose write-consult-majority Compare the performance and resilience of algorithms ConsensusSingle Value Consensus properties (4)Validity: Any value decided is a value proposedAgreement: No two correct nodes decide differentlytermination: Every correct node eventually decidesintegrity: A node decides at most once do not care about crashed nodes 怎样避免orphan message（之前propose的值后到了，不应该再decide了）Invariantadopt if proposer p is ranked higher than lastpropotherwise p has crashed and should be ignored Implements: Hierarchical Consensus(c)Uses:beb + P第几轮就是第几个process decide和broadcast Validity: Always decide own proposal or adpoted valueIntegrity: Rounds increase monotonically, A node only decide once in the round it is leaderTermincation: Every correct node makes it to the round it is leader, if some leader fails, completeness of P ensures progress. If leader correct, validity of BEB ensures deliveryAgreement: No two correct nodes decide differently How many failures can it tolerate? N-1 Uniform Consensus properties (4)Uniform Agreement (care about crashed nodes) Possible with weaker FD than P?Yes! use Strong Detector (S)Strong completenessWeak Accuracy: the “accurate” corect leader will BEB value and final decision is v by all Eventually perfect detector, cannot solveconsensus with resilience t ≥ n/2 PaxosSingle Value Uniform Consensus Validity (only proposed -&gt; decided) Uniform Agreement (No diff decide) Integrity (at most once) Termination (eventually decide a value) not solvable in Fail-Silent (aynchronous sytem model) 所以assumePartially synchronous system + fail-noisy model + Message duplication, loss, re-ordering use omega(evetual leader election to elect a single proposer) Proposer imposes its proposal to everyone Everyone decides问题是serveral processes might initially be proposers多个process都能propose使用abortable consensus 解决omega ensures evetually 1 proposer succeeds (liveness) PAXOSproposers (impose proposal to set of acceptors)acceptors (may accept values issued by proposers)learner (will decide depending on acceptors acceptances) centralized因为面临单点故障，不行 there will be a single proposer at least providing obstruction-free progress不能无脑选第一个distinguish proposals with unique seq number (ballot number)不能restart（这样就chose了两个值） P1 An acceptor accepts first proposal it receives (ensures obstruction-free progress and validity)P2 If v is chosen, every higher proposal chosen has value v (ensures agreement, integrity trivial to implement)P2a( lemma方便实现) every higher proposal accepted has value vP2b (加强) every higher proposal issued has value vP2c If any proposal (n,v) is issued, there is a majority set S of acceptors such that either(a) no one in S has accepted any proposal numbered less than n(b) v is the value of the highest proposal among all proposals less than n accepted by acceptors in S A proposer at round n needs a query phase to get the value of highest round number + a promise that the state of S does not change until round n 总体流程 proposer pick unique seq n, send prepare(n) to acceptors acceptors 承认不会接收n以下的proposals（freeze）, 发送最高n的accepted proposal proposer收到majority的promise, 取最高n的proposed value (如果没有就任取一个v（说明第一次）)进行accept(n, v) acceptor接收了(n, v)，如果无接收prepare m&gt;n, 则accept proposal (ack); 否则reject(nack) Proposer 接收到majority的response，decide否则abort 可能abort的点 Contention (multiple proposals competing) Message loss (not getting an ack) process failue (proposer dies) Optimizations Paxos (AC) in a nutshell Necessary:rej accept(n,v) if answered prepare(m): m&gt;n Optimizations: rej prepare(n) if answered prepare(m): m&gt;n rej accept(n,v) if answered accept(m,u): m&gt;n reject prepare(n) if answered accept(m, u): m&gt;n ignore old msgs to proposals that got majority Proposer skips the accept phase if a majority of acceptors return the same value vperformance++ 只要有stable storage可以应用到fail recover model RSM (Replicated State Machine)multi-paxos: ProCmds = {}Log = &lt;&gt;s0(initial state)proposed = false A client q wants to execute a command C, it reliably rb-broadcast &lt;C, Pid_q&gt; to all serversupon delivery &lt;C,Pid_q&gt; at pj, the command pair is added to ProCmds unless it is already in Log Validity● If process p decides v then v is a sequence of proposed commands(without duplicates)Uniform Agreement● If process p decides u and process q decides v then one is a prefix ofthe otherIntegrity● If process p decides u and later decides v then u is a strict prefix of vTermination (liveness)● If command C is proposed by a correct process then eventually everycorrect process decides a sequence containing C Agree on (non-duplicate) commandsallow to issue the same command C multiple times Initial statePropoer:np:=0 proposer’s current round numbervp:=&lt;&gt; proposer’s current value (empty sequence) Acceptor:npromise:=0 promise not to accept in lower roundsna:=0 round number in which a value is acceptedva:=&lt;&gt; accepted value(empty sequence) Learnervd:=&lt;&gt; decided value(empty sequence) 看ppt图 依然有一些问题● A proposer can run only one proposal until decide before taking thenext proposal. No pipelining of proposals● Multiple proposers may lead to live-locks (liveness violation)● Two round-trips for each sequence chosen use BLE to make a single proposer running for a longer period of time as a leader BLE1: Eventually every correct process trusts some correct correct process if a majority are correctBLE2: Eventually no two correct processes trust different correct processes We assume initially fail-noisybut net is weaker model that may drop msg and process crash and recover Majority requirement Each correct process will trust a leader only if the leader’s max ballot is among the collected ballots from a majority of processes Monotonically increasing ballotsEvery process p that do not receive the leader’s ballot (n, pidL) among collected ballots consider the leader has crashes p increases his own ballot (n+1, pidp) Eventual agreement&lt;=&gt; BLE2Completeness&lt;=&gt; BLE1 Leader Based Sequence PaxosAssume eventual leader election abstraction with a ballot number BLEBLE satisfies completeness and eventually accuracy and also monotonically unique ballots P4 inefficient 有多个proposer时，conflicts和restarts are likely (higher load -&gt; more conflicts) 2 round of msgs for each value chosen (Prepare, Accept) Solution: pick a leader (L,n) where n is a unique higher round number the leader acts as sole Proposer for round n After first Prepare (if not aborted) only perform Accepts until aborted by another Leader where n’ &gt; n Allow issuing and accepting multiple proposals in round n Initial State for Sequence Paxos ProposersnL=0, vL= leader’s current round number, proposed valuepropCmds=&lt;&gt; leader’s current set of proposed commands(empty set)las=[0]^N length of longest accepted sequence per acceptorlc=0 length of longest chosen sequencestate={(leader, prepare), (leader, accept), follower} Acceptornprom=0 Pomise not to accept in lower roundsna=0 round number in which a value is accpetedva=&lt;&gt; Accepted value(empty sequence) Learner Decide value(empty sequence) Removing redundancy of vL, va and vd removing vL:When p becomes a leader, it is possible to remove the need tostore the sequences vL and va separately at the leader removing vd: at decide phase add a new assumptionA3: FIFO Perfect Links partially sync for BLE but async for LBSP ReconfigurationA replicated state machine is running on a set of N processes Impossible to know if a process is faulty or slow in asychronous system must be able to replace any process this is called reconfiguration Each configuration is conceptually an instance of Sequence-Paxosreplicas in configuration c1 = {r11,r12,r13,r14}A process may act as multiple replicas in different configurationse.g. p1 is {r01, r11, r21} if seq v is issued in round n then v is an extension of all sequences chosen in rounds &lt;= n stop-sign - last command - final sequence rij: replica j in config i Overlapping configurations A process have replicas in multiple configurationsBut can only be running in one configuration at anytime Time and Clocks in DSMotivation for using physical clocksConsider a slightly stronger system model: Computation: no bounds on time to take a step Communication: no bounds on latency Clocks: Lower and upper bounds on clock rate Time-based leader leases network partition P17one is elected as leader but the original leader never hears about that A propose p to become leader: sends a request (prepare) to acceptors An acceptor gives a time-based leader lease to p, lasting for 10 seconds If a proposer gets leases from a majority of acceptors, then proposer holds lease on group and becomes a leader In the time until the first acceptor lease expires, the proposer knows that no other proposer can hold the lease on the group此时leader可以从local state里读然后直接返回 两个问题asynchronous networkclock drift P34如果proposer（receive lease的人）时钟比较快，那么leader会先取消自己的时钟，所以不会影响safety 反之，如果acceptor（give lease的人）时钟比较快，就会影响safety Shared memory using clocks Review of shared memory:Leases at proposerThe Read-Impose Write-Consult_Majority algorithm does 2 round-trips to a majority of processes for both reads and writes… need synchronized clocks Interval ClocksCi(t) = (lo, hi) the correct time t is guaranteed to be in intervalCi(t).lo &lt;= t &lt;= Ci(t).hi Ci read at t1, Cj read at t2, and t1 &lt; t2Ci(t1).lo &lt; Cj(t2).hi use ICs to remove query phase in write operations p1 must wait until ts(o1).t &lt;= C1(t1).lo ts(o2).t = C2(t2).hi (invoke write o2) 因为t1 &lt; t2 所以 C1(t1).lo &lt; C2(t2).hiHence: ts(o1) &lt; ts(o2) Consistent Snapshotfailure recovery and reconfiguration SNAP -&gt; Restart system from snapshot -&gt; restart system with new configuration S1: Termination: Eventuallt every process records its stateS2: Validity: All recorded states correspond to a consistent cut of the execution Chandy Lamport Algorithm FIFO Reliable Channels Single Initiating Process pi Strong Connectivity 强连通 Design goal:Obstruction-free: run concurrently but not alter underlying computation Intuition:Disseminate a special message to mark events before and after the consistent cut Termination is still satisfied if the protocol is initiated by a set of processes that can reach all tasks. Epoch Snapshotting:make production-grade data processing systems reliable Previous approaches Complex Workarounds (e.g., duplicate elimination, input logging, acks) Strong Assumptions (idempotent operations, key vs task level causal order) External State Management (transactional external commits per action Epoch-based stream execution the intuitionfor each epochinput: deterministic input streams &amp; task statesstream processing systemsuccess: commit system configurationfailure: abort and start from previous epoch consistent cut is not enoughepoch cut support the large stream processing system]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dirty read, phantom read, and unrepeatable read]]></title>
    <url>%2Fblog%2F2021%2F02%2F22%2Fdirty-read-phantom-read-and-unrepeatable-read%2F</url>
    <content type="text"><![CDATA[dirty read, phantom read, and unrepeatable read 脏读dirty read：读取未提交的数据。B发起事务，B写后，A读（读取未提交的数据），但B之后回滚了，再提交，A再读，不一致。 不可重复读unrepeatable read：前后多次读取不一致。A读，B写，B提交，A再读，不一致。针对update操作。 幻读phantom read：前后多次读取，数据总量不一致。A读数据库行数，B插入或删除某一行，A再读行数，不一致。 针对insert和delete操作 解决方案： 根据数据库事务四大性质中的隔离性：隔离性级别被分为read_uncommit，read_commit，read_repeatable，Serializable用以解决以上的问题。它们的区别是：read_uncommit没有解决任何问题，read_commit解决了脏读，read_repeatable解决了脏读和不可重复读，Serializable解决了三种情况。 read_commit：在上文的情况下，B写的整个事务周期，A都不能读。只有B发起事务前和提交事务后A才能读，这样就不会出现B写时A读从而读取不一致的情况。（Sql Server , Oracle使用的就是read_commit级别） read_repeatable: 保证了不出现脏读，并且保证不可重复读。A读时，就对行加锁，B不能写这条数据。直到A多次读完后，B才能写。（MySQL使用的就是read_repeatable级别）123/* （参数可以为：Read uncommitted，Read committed， Repeatable，Serializable） */SET session TRANSACTION ISOLATION LEVEL Repeatable;SELECT `id` FROM `users` WHERE `id` = 1 FOR UPDATE; serializable：保证了不出现脏读、不可重复读和幻读。A读时，对表加锁，B不能添加或删除其它数据行。1SET session TRANSACTION ISOLATION LEVEL Serializable; 参考 https://cloud.tencent.com/developer/article/1450773 https://segmentfault.com/a/1190000016566788]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Disributed Framework and Dubbo]]></title>
    <url>%2Fblog%2F2021%2F01%2F28%2FDisributed-Framework-and-Dubbo%2F</url>
    <content type="text"><![CDATA[Distributed Framework and Dubbo What is Distributed System?a collection of independent comptuters which serve like a coherent system to users. Framework transition and why we need Distributed Framework?All in One ArchitectureInitially, we have one simple application, on which all the functionalities are integrated, when we have only a few users. At that time, ORM is necessary because it simplify the CRUD processes. When there are more and more users, we surely need more servers to bear more pressure (One application Multiple servers). Therefore we need more servers ro bear the pressure together (use Ngnix to balance overload). However that will cause two problems: Difficult to extendWhen we modify one func of one server, we need to package the whole application again to other servers. Difficult to collaborate Vertical Architecturedifferent modules of applications (e.g. User/Shopping Cart/Payment), assign different number of servers to modules based on demands. We will meet the problems and we should also: View/ Logics should be divided Applications cannot be fully seperated, some should interact RPC ArchitectureBut there yield another problem, how to interact between Web view and Services logics as they are divided? Answer: Use RPC (Remote Process Call). Therefore, we need a distributed service framework to handle the RPC. And we also need a scheduler to balance the load. RPC problemsRPC is a method that used by one service on one server A to call the procedure on another server B. Both server A and B should have its own stub (helper) to handle the sending messages(functions/parameters)and returning messages(results). The RPC is an aynchronous process. To send or receive the messages the stub should firstly serialize or deserialize the objects. The core problems in an RPC framework: how efficient to establish connection how efficient to serialize/deserialize RPC framework - Dubbohttps://dubbo.apache.org/en/ Dubbo is a framework with following features: Interface-based High-performance RPC Intelligent load balance Automatic service registration and discovery (“recommend”) High extensibility (micro-kernal and plugin design) Runtime traffic routing (blue-green deployment, some requests use new services, some use old services) Visualization]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Byzantine Leader Election]]></title>
    <url>%2Fblog%2F2021%2F01%2F24%2FByzantine-Leader-Election%2F</url>
    <content type="text"><![CDATA[Why in Byzantine Leader Election, N &gt; 3f GivenN: number of the processesf: number of the Byzantine processes In the paper “Practical Byzantine Fault Tolerance”, we get the conclusion that 3f+1 is the minimum number of replicas that allow an asynchronous system to provide the safety and liveness properties when up to f replicas are faulty. This many replicas are needed because it must be possible to proceed after communicating with n-f replicas, since f replicas might be faulty and not responding. However, it is possible that the f replicas that did not respond are not faulty and therefore f of those that responded might be faulty. Even so, there must still be enough responses that those from non-faulty replicas outnumber those from faulty ones, i.e., n-2f&gt;f. Therefore n&gt;3f. 理解起来其实很困难，总给人一种哪里不对的感觉。比如为什么不能直接大多数N &gt; 2f 就能解决呢？只要有f+1个正确节点都表态(+)，即使有f个拜占庭节点都投反对票(-)，那正确节点也占多数，最后不也达成了正确的一致性吗？ 但是这忽略了系统的一个根本问题：什么时候才能达成一致性呢？拜占庭节点之所以叫拜占庭节点，就是说它所做的是不可控的（表态可以是表态+或-或者干脆不表态）。也就是说，如果我规定某个节点A（可能是正常也可能是拜占庭节点）要知道大多数的意见，A需要收集N个消息（包括自己），但是拜占庭可能不回复，因此就永远收集不了N-1个消息，无限等待。另一方面，不考虑拜占庭节点，A只要一收集到N-f（除去可能crash的拜占庭节点）个消息即可形成一个quorum，然后按大多数投票来表态，可是这样万一拜占庭节点没有crash，只不过是其它正常节点发晚了呢？那A可能在当前形成的quorum中占少数派，拜占庭节点占大多数，然后就会达成错误的共识了。这就陷入了一个困境。 因此，考虑到拜占庭节点的不确定性，除了本身N-f即形成quorum，我们还要考虑回复消息的至多f个拜占庭节点，除去这些节点，也即N-2f这些节点必是正确节点，这些节点的个数要大于f个拜占庭节点从而形成正确的consensus，也即N-2f&gt;f，也即N&gt;3f。]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVM公式推导和原理解析]]></title>
    <url>%2Fblog%2F2020%2F12%2F16%2FSVM%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E5%92%8C%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[SVM公式推导和原理解析]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多分类AUC计算]]></title>
    <url>%2Fblog%2F2020%2F11%2F07%2F%E5%A4%9A%E5%88%86%E7%B1%BBAUC%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[一般涉及到的是binary classification的AUC计算,这里给出的计算方法即可用于binary也可用于多分类问题。 input: 给定的dataframe, 实际预测的correctlabelsoutput: AUC 面积 举个例子，给定的dataframe是 d A B C 0 0.50 0.50 0.00 1 0.50 0.25 0.25 2 0.50 0.25 0.25 3 0.25 0.50 0.25 4 0.25 0.25 0.50 A,B,C代表三个类，其中的数字代表着预测该类的概率 而corrrectlabels也即实际预测的结果是[“B”,”A”,”B”,”B”,”C”]这两者作为input可以计算output的AUC面积 以下是求面积的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071def find_pos_neg_instance_scores(prediction_column, correct_labels, column_name): prediction_column_array = np.array(prediction_column) binary_AUC = [column_name == i for i in correct_labels] print('binary_AUC=', binary_AUC) # positive_instance_scores =&gt; Col-Name (predicted class) matches with the correct class positive_instance_scores = prediction_column_array[binary_AUC] # negative_instance_scores =&gt; Col-Name (predicted class) DOES NOT match with the correct class negative_instance_scores = prediction_column_array[~np.array(binary_AUC)] print(positive_instance_scores) print(negative_instance_scores) return positive_instance_scores, negative_instance_scores# fpr=False_Positive_Rate# tpr=True_Positive_Ratedef get_tpr_fpr(prediction_column, correct_labels, column_name): positive_instance_scores, negative_instance_scores = find_pos_neg_instance_scores(prediction_column, correct_labels, column_name)# print(positive_instance_scores)# print(negative_instance_scores) scores_extended = [0] scores_extended += sorted(prediction_column) scores_extended += [1] print('scores_extended=',scores_extended) dict_tpr_fpr = &#123;&#125; for predicted_score in scores_extended: if(len(negative_instance_scores)==0): count_false_pos_instances = 0 else: count_false_pos_instances = np.sum(negative_instance_scores &gt;= predicted_score)/len(negative_instance_scores) if(len(positive_instance_scores)==0): count_true_pos_instances = 0 else: count_true_pos_instances = np.sum(positive_instance_scores &gt;= predicted_score)/len(positive_instance_scores) #dict_tpr_fpr[predicted_score] = [count_false_pos_instances, count_true_pos_instances] dict_tpr_fpr[predicted_score] = [count_true_pos_instances, count_false_pos_instances] print('dict_tpr_fpr=',dict_tpr_fpr) list_reversed_tpr_fpr = [i for i in reversed(list(dict_tpr_fpr.values()))] print('list_reversed_tpr_fpr=', list_reversed_tpr_fpr) return list_reversed_tpr_fprdef calculate_AUC(list_reversed_tpr_fpr): # AUC = Area under ROC curve AUC = 0 n_tpr_fpr = len(list_reversed_tpr_fpr) for i in range(n_tpr_fpr - 1): if(list_reversed_tpr_fpr[i][1] != list_reversed_tpr_fpr[i + 1][1]): # if fpr is changing but tpr is not changing then the area is a square=a*b=(tpr[i+1]-0)*(fpr[i+1]-fpr[i]) if(list_reversed_tpr_fpr[i][0] == list_reversed_tpr_fpr[i + 1][0]): AUC += list_reversed_tpr_fpr[i + 1][0]*(list_reversed_tpr_fpr[i + 1][1] - list_reversed_tpr_fpr[i][1]) else: # if both are changing then the area is a trapezoid=(a+b)*h/2=(tpr[i]+tpr[i+1])*(fpr[i+1]-fpr[i])/2 AUC += (list_reversed_tpr_fpr[i + 1][0] + list_reversed_tpr_fpr[i][0])*(list_reversed_tpr_fpr[i + 1][1] - list_reversed_tpr_fpr[i][1])/2 return AUC def auc(df, correctlabels): AUC = 0 class_frequency = dict() for i in correctlabels: if i not in class_frequency: class_frequency[i] = (1/len(correctlabels)) else: class_frequency[i] += (1/len(correctlabels)) for col in df.columns: prediction_vector = df[col] list_reversed_tpr_fpr = get_tpr_fpr(prediction_vector, correctlabels, col) area_col = calculate_AUC(list_reversed_tpr_fpr) AUC += class_frequency[col] * area_col return AUC 测试代码:12345predictions = pd.DataFrame(&#123;"A":[0.5,0.5,0.5,0.25,0.25],"B":[0.5,0.25,0.25,0.5,0.25],"C":[0.0,0.25,0.25,0.25,0.5]&#125;)correctlabels = ["B","A","B","B","C"]print("AUC: &#123;&#125;".format(auc(predictions,correctlabels))) 步骤说明：第一步即调用auc方法计算class_frequency，即利用frequency作为权重将所有类的AUC相加。(Calculate the weighted AUC by summing the individual AUCs weighted by the relativefrequency of each class (as estimated from the correct labels) 接下来就是计算每个类的AUC了,实际上是每个类的binary AUC, 也即对于这个类的FPR和TPR点所围面积的和 概念链接。 因此，首先我们必须计算TPR和FPR点的坐标，也就是get_tpr_fpr函数，先找到其中判断对positive与错negative的scores（find_pos_neg_instance_scores函数），再对prediction_column（这里需要在首尾加一个0和一个1，好帮助后面的面积计算）中的每个prediction_score，判断它和判断negative 或positive instance的score的关系。得到count_false_pos_instances和count_true_pos_instances的两句实际上就是FPR（在所有实际为阴性的样本中，被错误地判断为阳性之比率FPR=FP/(FP+TN)）和TPR（在所有实际为阴性的样本中，被错误地判断为阳性之比率TPR=TP/(TP+FN)）的计算过程。 这一步之后再进行个从小到大的排序，其实就得到了所有的score对应的TPR和FPR pair 也即点坐标，只要画出点坐标连接后下方在坐标轴上的面积（以TPR为纵轴，FPR为横轴），就可以得到AUC的面积了。而这一步则用calculate_AUC函数自动计算得到。 得到了每一个类的AUC，再做一个weight sum就是最后的多分类AUC面积。 更简单的多分类方法（概率方法）：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def auc(df,correctlabels): new_df=df.copy() lens=len(correctlabels) cols=new_df.columns.tolist() if len(cols)&lt;3: #binary ;only Pos and Neg pos=[ i for i in range(lens) if correctlabels[i]==cols[0]] neg=[i for i in range(lens) if correctlabels[i]!=cols[0]] print(pos,neg) one=new_df[cols[0]] auc = 0 for i in pos: for j in neg: if one[i] &gt; one[j]: auc += 1 elif one[i] == one[j]: auc += 0.5 return auc / (len(pos)*len(neg)) else: # CLASS &gt;=3 Pos / non-Pos aucs=[] for col in cols: pos=[ i for i in range(lens) if correctlabels[i]==col] nonpos=[i for i in range(lens) if correctlabels[i]!=col] print(pos,nonpos) one=new_df[col] auc = 0 for i in pos: for j in nonpos: if one[i] &gt; one[j]: auc += 1 elif one[i] == one[j]: auc += 0.5 auc=auc/(len(pos)*len(nonpos)) aucs.append(auc) weights=[correctlabels.count(col)/len(correctlabels) for col in cols ] print(weights) print(aucs) weights=np.array(weights) aucs=np.array(aucs) avg_auc=np.sum(aucs*weights) return avg_auc# testpredictions = pd.DataFrame(&#123;"A":[0.5,0.5,0.5,0.25,0.25],"B":[0.5,0.25,0.25,0.5,0.25],"C":[0.0,0.25,0.25,0.25,0.5]&#125;)correctlabels = ["B","A","B","B","C"]print("AUC: &#123;&#125;".format(auc(predictions,correctlabels))) 简单的二分类AUC计算12345678910111213141516171819def cal_auc(prob, labels): f = list(zip(prob, labels)) rank = [values2 for values1, values2 in sorted(f, key=lambda x: x[0])] rankList = [i + 1 for i in range(len(rank)) if rank[i] == 1] posNum = 0 negNum = 0 for i in range(len(labels)): if (labels[i] == 1): posNum += 1 else: negNum += 1 auc = (sum(rankList) - (posNum * (posNum + 1)) / 2) / (posNum * negNum) return auc# testmodel = BernoulliNB()model.fit(x_train, y_train)prediction = model.predict_proba(x_val)auc = cal_auc(prediction[:, 1], np.array(y_val))]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[computer network]]></title>
    <url>%2Fblog%2F2020%2F08%2F03%2Fcomputer-network%2F</url>
    <content type="text"><![CDATA[计算机网络知识点 用户态（应用层HTTP,FTP,DNS,HTTPS)核心态(传输层tcp, 网络层ip, 链路层) 二、链路层 功能：将上层数据封装成帧，用MAC地址访问媒介，错误检测与修正 以太网帧格式7字节前导码（同步）1字节帧开始符6子节MAC目标地址6子节MAC源地址一个4子节标签（可选）2字节以太类型（0x0800 IPv4; 0x0806 ARP)负载46-1500字节CRC冗余校验帧间距12字节 MTU（Maximum transmission Unit) 数据链路层最大数据包大小，单位：字节。即无需进一步分片就能穿过这条“路径”的最大传输单元的最大值。如果不要分片，设置数据报的DF位（Don’t fragment），路径上任何需要将分组进行分片的设备都会将这种数据报丢弃并返回一个“数据报过大”的ICMP响应到源地址。 arp协议 address resolution protocol 实现ip地址到MAC地址的映射，即询问目标IP地址对应的MAC地址，然后放入ARP缓存表。原理：把带有目标ip地址的arp请求广播到局域网上所有主机，并接受响应获取mac地址。存入arp缓存表一段时间。目的MAC地址：占6字节，表示接收方设备的硬件地址，在请求报文中该字段值全为0，即00-00-00-00-00-00，表示任意地址，因为现在不知道这个MAC地址。 基于功能来考虑，ARP是链路层协议；基于分层/包封装来考虑，ARP是网络层协议（2字节以太类型（0x0800 IPv4; 0x0806 ARP)） 三、网络层功能：1、路由选择（规划路线）2、存储、交换、转发（路由器通过路由表转发包，如果接收速度大于转发速度就缓存）3、拥塞控制 4、呼叫准入（所有路由器的许可） ip首部格式：如图第二行，16位序列号：如有分片，下一个序列号与上一个相同，若无分片，下一个序列号等于上一个加一。3三个bit位：第一位保留，未使用。第二位是DF（Don’t Fragment），如果为1，表示未发生分片。第三位是MF（More Fragment），如果为1，表示发生了分片，并且除了分片出的最后一个报文中此标志为0，其余报文中此标志均为1。13位片位移：分片相对于原始ip数据报开始处的偏移。 8位生存时间TTL（time to live), 防止数据报兜圈子，不断减去在路由器间传递的时间，直到零就丢弃数据报，不再转发。 16位首部检验和 掌握IP分片一个长4000B的IP数据报，数据部分3980B,到达了一个路由，需要转发到一个MTU为1500B的链路上，这样就得分片了。分片数目是3片。每个片都是一个数据报。假设标识是777，那么数据报分片结果是：分片一：标识：777，MF=1，DF=0,片偏移=0，有效数据：1480B(编号0~1479)分片二：标识：777，MF=1,DF=0,片偏移=185，1858=1480，有效数据：1480B(编号1480~2959)分片三：标识：777，MF=0,DF=0,片偏移370，3708=2960，有效数据：1020B(编号2960~3979) IP路由表 分组转发流程 从数据报首部提取主机的IP地址D，得到目的网络地址N（子网掩码存储在路由表中，与IP地址D进行逻辑与即可得到N） 若N是与此路由器直接相连的某个网络地址，直接交付 若路由表中有目的地址为D的特定主机路由/到达网络N的路由，则把数据报传送给表中指明的下一跳路由 若路由表中有一个默认路由，则把数据报传送给路由表所指明的默认路由器 报告转发分组出错 IP内部网关协议RIPRIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 ICMP查询2种+差错5种 四、传输层UDP协议：特点，首部字段 TCP协议：特点+首部字段+可靠机制首部（校验和。。。） 连接基础 三次握手 目的：为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。主要防止资源的浪费。 四次挥手（为什么） 关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，我们也未必全部数据都发送给对方了，所以我们不可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，我们的ACK和FIN一般都会分开发送。 同时打开、同时关闭、半关闭 服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。来源链接 tcp流量控制机制：滑窗、 在未收到ACK确认之间都必须暂时保留在发送窗口内，以便超时重传使用 慢启动、拥塞避免、快速重传、快速恢复超时重传 伪包头 五、应用层域名解析DNS协议名字空间、DNS指针查询（反向查找或逆向解析）、DNS缓存 DNS查询过程实例1）客户端将www.redhat.com的查询提交给本地DNS服务器（递归查询）。2）本地DNS服务器检查区域数据库，由于该服务器没有redhat.com的授权，它将查询传递到根服务器（“.”DNS服务器），请求解析主机名称。根名称服务器把“com”DNS服务器IP地址返回给本地DNS服务器（迭代查询）。3）本地DNS服务器将请求发给“com”DNS服务器，该服务器根据请求将“redhat.com”DNS服务器IP地址返回给本地DNS服务器（迭代查询）。4）本地DNS服务器向“redhat.com”DNS服务器发送请求，由于该服务器具有“www.redhat.com”记录，它将www.redhat.com的IP地址返回给本地DNS服务器。5）本地DNS服务器将www.redhat.com的IP地址发送给客户端。 FTP数据流、控制流：端口20用于在客户端和服务器之间传输数据流，而端口21用于传输控制流 两种工作模式：PASV+PORT 1、主动FTP：命令连接：客户端 &gt;1024端口 -&gt; 服务器 21端口数据连接：客户端 &gt;1024端口 1024端口 -&gt; 服务器 21端口 数据连接：客户端 &gt;1024端口 -&gt; 服务器 &gt;1024端口 我自己的理解是主动模式的话，客户端随意起一个大于1024端口去连服务器的21端口，然后告诉服务器我已经准备好数据连接了，你过来连我的数据端口吧，然后服务器用自己的20端口去连客户端的端口，注意此时客户端其实为了响应，是随意启用了一个自己不用的端口，即大于1024的端口。 被动模式：从头到尾都是客户端去连服务器，服务器一直处于响应状态。客户端打开两个大于1024的端口，然后第一个端口去连服务器的21号端口，告诉服务器：“你准备好了吗？我要向你传输数据了。然后服务器说我好了，客户端用自己事先开好的第二个端口去连接服务器，注意此时服务器的数据端口已经不是20了，服务器为了响应请求，随机开了一个大于1024端口(https://blog.51cto.com/9237101/1911032) FTP指令和响应码FTP断电续传、匿名ftp HTTP报文格式：请求报文、响应报文、请求头各种字段、响应头各种字段http状态码 HTTPS详细握手摘要算法、数字签名、数字证书]]></content>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go基础]]></title>
    <url>%2Fblog%2F2020%2F07%2F21%2Fgo%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[go programming 基础 Why go1.Code run fast2.Garbage collection3.Simpler objects4.Concurrency is efficient Software Translation machine language: CPU instructions represented in binary Assembly language: CPU ~ with mnemonics (easier to read) High level language CompilationTranslate instructions while code is executed C++, C, Java (compiler) Translation occurs once Java(compiled to bytecode then be interpreted), Python (interpreter) Translation occurs every execution ObjectsGo is weakly OOP language Go use structs instead of class No contructor, generics and inheritance ConcurrencyPerformance Limits:Moore’s LawMore transistors used to lead to higher clock frequenciesPower/temperature constraints ParallelismGPU thounsands of cores Concurrency is the management of multiple tasks at the same time Key requirement for large systems Concurrent programming enables parallelism-&gt; Management of task execution-&gt; Communication between tasks-&gt; Synchronization between tasks Go includes concurrency primitivesGoroutines represent concurrent tasksChannels are used to communicate between tasksSelect enables task sysnchronizationConcurrency primitives are efficient and easy to use InstallationPackage Main12345package mainimport "fmt"func main()&#123; fmt.Printf("hellow world\n")&#125; Commands: go build - compiles the program to .exe file go doc print documentation go fmt format indentation go get package go run go test Variablevar x int = 100var x, y int = 100 var x = 100 (auto infer) x := 100 Define and alias for a typetype Celsius float64type IDnum int PointerA pointer is an address to data in memory &amp; returns the address of a variable/function * operator returns the data at the address123456var x int = 1var y intvar ip *intip = &amp;xy = *ip New new() function creates a variable and returns a pointer to the variable12ptr := new(int)*ptr = 3 1fmt.Printf("Hi %s", x) x = int32(y) String PackageCompareTo(a, b) Contains(s, substr) HasPrefix(s, prefix) Index(s, substr) Replace(s, old, new, n) ToLower(s) TrimSpace(s) returns a new string Strconv PackageAtoi(s) -converts string s to int Itoa(s) -convert int to string FormatFloat(f, fmt,prec, bitSize) - convert flot to string ParseFloat(s, bitSize) - Converts a string to a floating point number Constants Expression whose value is known at compile time Type is inferred from righthand side (boolean, string number)12345const x = 1.3const( y=4 z="Hi") iota (like enumerate) generate a set of related but distinct constants Ofter represents a property which has several distinct values123456789101112131415161718type Grades intconst( A Grade = iota // 0 B // 1 C // 2 D F)type Allergen intconst ( IgEggs Allergen = 1 &lt;&lt; iota // 1 &lt;&lt; 0 which is 00000001 IgChocolate // 1 &lt;&lt; 1 which is 00000010 IgNuts // 1 &lt;&lt; 2 which is 00000100 IgStrawberries // 1 &lt;&lt; 3 which is 00001000 IgShellfish // 1 &lt;&lt; 4 which is 00010000) Control flow123if x &gt; 5&#123; fmt.Printf("aa")&#125; 123for i:=0; i&lt;10; i++&#123;&#125; 12345678switch x&#123; case 1: fmt.Printf("") case 2: fmt.Printf("") default: fmt.Printf("nocase") // auto break&#125; Scan Scan reads user input Takes a pointer as an argument Typed data is written to pointer Returns number of scanned item 12345var appleNum intfmt.Printf("Number of apples?")num, err := fmt.scan(&amp;appleNum)fmt.Printf(appleNum) Composite Data typesArrays: fixed length12345678910var x [5]intx[0] = 2var x [5]int = [5]&#123;1,2,3,4,5&#125;x:=[...]int&#123;1, 2, 3, 4&#125; // infers size from number of initializersfor i, v := range x&#123; fmt.Printf("ind %d, val %d", i, v)&#125; Slices A “window” on an underlying array Variable size, up to the whole array Pointer indicates the start of the slice Length Capacity is the max number of elts(elements) 1234arr := [...]string&#123;"a", "b", "c", "d", "e", "f", "g"&#125;s1:=arr[1:3]s2:=arr[2:5]fmt.Printf(len(s1), cap(s))// 3 7 1sli := []int&#123;1,2,3&#125; // this is a slice because no ... or number in the bracket init a slice directly make() 123sli := make([]int, 10) // 10 is the lengthsli := make([]int, 10, 15) // 15 is the capacity append() 1sli = append(sli, 100) Maps Implementation of a hash map 123456789101112131415161718var idMap map[string][int]idMap = make(map[string]int)idMap := map[string]int&#123; "joe": 123&#125;idMap["joe"] = 456delete(idMap, "joe")id, p := idMap["joe"] // id is value, p is True/False the key in the maplen(idMap)for key, val := range idMap&#123; fmt.Println(key, val)&#125; structsPerson StructName, Address, phone 12345678910111213141516type struct Person&#123; name string addr string phone string&#125;var p1 Person// dot notation to access struct fieldsp1.name = "joe"x1 = p1.addr// init a structp1 := new(Person)p1 := Person(name: "joe", addr: "a st.", phone: "123") Protocols and Format Request for Comments (RFC) Definition of Internet protocols and formate.g. HTML Hypertext Markup Language URI Uniform Resource Identifier HTTP Hypertext Transfer Protocol 12345import "net/http"http.Get(www.baidu.com)import "net"net.Dial("tcp", "uci.edu:80") //make a tcp connect with the url JSONJavaScript Object Notation Go structp1 := Person(name:”joe”, addr: “a st.”) equivalent JSON object{“name”:”jow, “addr”:”a st.”} 12345p1 := Person(name:"joe", addr:"aaa")barr, err:=json.Marshal(p1)var p2 Personerr := json.Unmarshal(barr, &amp;p2) Marshal() returns JSON representation as []byte Unmarschal() pointer passed to GO object and object must fit JSON []byte Files (Read, Write) Linear access, not random access Open, Read, write close seek(move read/write head) ioutil File Read 123456dat, e := ioutil.ReadFile("test.txt") // content, error// Explicit open/close are not needed// Large files cause a problem (in RAM)dat = "JoJO"err:= ioutil.WriteFile("out.txt", dat, 0777) // permission os.Open() os.Close() os.Read() reads from a file into byte[] os.Write() 1234f, err := os.Open("dt.txt")barr :=make([]byte, 10) // read 10 bytenb, err := f.Read(barr)f.Close() 12345f, err := os.Create("outfile.txt")barr:=[]byte&#123;1,2,3&#125;nb,err:=f.Write(barr) // write any unicode sequencenb,err:=f.WriteString("Hi") Functions123func main()&#123; fmt.Printf("Helllo, world.") // main function called automatically&#125; Abstraction is hiding details that are less important Call by Reference12345678func foo(y *int)&#123; *y = *y + 1&#125;func main()&#123; x:=2 foo(&amp;x)&#125; pros: copying time(no need to pass a whole array)cons: data encapsulation Passing Array Arguments1234567891011121314151617181920212223242526272829func foo(x [3]int) int&#123; return x[0]&#125;func main()&#123; a:=[3]int&#123;1,2,3&#125; fmt.Print(foo(a))&#125;// modify by passing array pointers (messy and unnecessary)func foo(x *[3]int)int&#123; (*x)[0] = (*x)[0] + 1&#125;func main()&#123; a:=[3]int&#123;1,2,3&#125; foo(&amp;a) fmt.Print(a)&#125;// using slices in go!!!func foo(sli []) int&#123; sli[0] = sli[0] +1&#125;func main()&#123; a := []int&#123;1,2,3&#125; // no size foo(a) fmt.Print(a)&#125; First-Class Values Functions can be treated like other types Variables can be declared as a func 12345678910var funcVar func(int) intfunc incFn(x int) int&#123; return x+1&#125;func main()&#123; funcVar = incFn fmt.Print(funcVar(1))&#125; Functions as Arguments 123func applyIt(afunct func(int) int, val int) int&#123; return afunct(val)&#125; Anonymous Functions 12345678func applyIt(afunct func(int) int, val int) int&#123; return afunct(val)&#125;func main()&#123; v:= applyIt(func (x int) int &#123;return x+1&#125;, 2) fmt.Println(v)&#125; Function Defines a Functionex: compute the distance between a point to a origin (variable) 1234567891011121314func MakeDistOrigin(o_x, o_y float64) // 参数类型 func(float64, float64) float64&#123; // 返回类型是一个函数 fn := func(x, y float64) float64&#123; return math.Sqrt(math.Pow(x-o_x, 2) + math.Pow(y-o_y, 2)) &#125; return fn&#125;func main()&#123; Dist1 := MakeDistOrigin(0,0) // return a function which can compute the distance from given point to (0,0) Dist2 := MakeDistOrigin(2,2) fmt.Println(Dist1(2,2)) fmt.Println(Dist2(2,2))&#125; environment along with a function Closure function + its environment when functions are passed/ returned, their environment comes with them in the previous exampleo_x, o_y are the environment 闭包的好处 希望一个变量长期保存内存中 避免全局变量污染 私有成员的存在。 12345678910111213141516171819// 拍卖func makeComparePrice() func(float64) float64 &#123; // 返回类型是一个函数,指定这个函数的参数类型和返回类型 o_price := 5.0 // := 是申明新的变量并赋值 fn := func(price float64) float64 &#123; if o_price &lt; price &#123; o_price = price // =是改变原来的o_price,这里不能使用o_price := price这样就是新的一个o_price &#125; return o_price &#125; return fn&#125;func main() &#123; comparePrice := makeComparePrice() fmt.Println(comparePrice(4)) // 5 fmt.Println(comparePrice(6)) // 6 fmt.Println(comparePrice(980.424)) // 980.424 fmt.Println(comparePrice(1.23)) // 980.424&#125; Variadic and Deferred variable argument number 123456789101112131415func getMax(val ...int) int&#123; maxV := -1 for _, v := range vals&#123; if v&gt;maxV&#123; maxV = V &#125; &#125; return maxV&#125;func main()&#123; fmt.Println(getMax(1,3,6,4)) vslice := []int&#123;1,3,6,4&#125; fmt.Println(getMax(vslice...))&#125; defer calling function 123456func main()&#123; i:=1 defer fmt.Prinln(i+1) // 2 i++ fmt.Println("Hello"!)&#125; Classes and EncapsulationEncapsulation data can be protected from the programmer data can be accessed by only methods Associating Methods with Data Method has a receiver type that it is associated with Use dot notation to call the method 12345678910type MyInt intfunc (mi MyInt) Double() int&#123; // MyInt is the receiver type, this type has a method named Double(), we can call it by dot notation return int(mi*2)&#125;func main()&#123; v:=MyInt(3) fmt.Println(v.Double())&#125; use struct12345678910111213141516//Point typetype Point struct&#123; x float64 y float64&#125;// 为Point类定义一个方法func (p Point) DistToOrig()&#123; t := math.Pow(p.x, 2) + math.Pow(p.y,2) return math.Sqrt(t)&#125;func main()&#123; p1 := Point(3,4) fmt.Println(p1.DistToOrig())&#125; Controlling Access123456789package datavar x int = 1func PrintX()&#123;fmt.Println(x)&#125;package mainimport "data"func main()&#123; data.PrintX()&#125; Controlling Access to Structs12345678910111213141516171819202122package datatype Point struct&#123; x float64 y float64&#125;func (p *Point) InitMe(xn, yn float64)&#123; p.x = xn p.y = yn&#125;func (p *Point) Scale(v float64)&#123; p.x = p.x* v p.y = p.y* v&#125;package mainfunc main()&#123; var p data.Point p.InitMe(2,3) p.Scale(2)&#125; 1234567891011121314151617// wrong, just the copy, do not change x coord at allfunc main()&#123; p1 := Point(3, 4) p1.OffsetX(5)&#125;// large receiver!!type Image [100][100] intfunc main()&#123; i1:= GrabImage() il.BlurImage() // 10000 ints copied to BlurImage()&#125;// 正确func(p *Point) Offset(v float64)&#123; p.x = p.x + v&#125; Polymorphism Ability for an object to have different forms depending on the context OverridingSubclass redefines a method inherited from the superclass -polumorphic Interfaces Name, parameters, return values Implementation is NOT defined Satisfying an Interfaceimplement all the methods(similar to inheritance with overriding) additional functions permitted 123456789type Shape2D interface&#123; Area() float64 Perimeter() float64&#125;type Triangle&#123;...&#125;func(t Triangle) Area() float64&#123;...&#125; // match to the func in Shape2D interface automaticallyfunc(t Triangle) Perimeter float64&#123;...&#125; Concrete vs Interface Types(data &amp; methods) vs (methods) 1234567891011121314151617type Speaker interface &#123;Speak()&#125;type Dog struct &#123;name string&#125;// 实现Speaker里的Speak函数，无需指定Speaker名。有一个associated type是实现类型Dog// x相当于Dog实现了Speaker的Speak函数func (d Dog) Speak()&#123; fmt.Println(d.name)&#125;func main()&#123; var s1 Speaker var d1 Dog&#123;"Brian"&#125; s1 = d1 s1.Speak()&#125; // var d1 *Dog //legal, d1 has no concrete value, ca still call the Speak()1234567891011func (d*Dog) Speak()&#123; if d == nil&#123; fmt.Println("&lt;noise&gt;") &#125; else&#123; fmt.Println(d.name) &#125;&#125;var s1 Speakervar d1 *Dogs1 = d1s1.Speak() 12345678910111213141516171819202122232425262728293031// 任意实现Shape2D的图形都可以用func FitInYard(s Shape2D) bool&#123; if(s.Area()&gt;100 &amp;&amp; s.Perimeter()&gt;100)&#123; return true &#125; return False&#125;// 不同图Type不同功能func DrawRect(r Rectangle)&#123;...&#125;func DrawTriangle(t Triangle)&#123;...&#125;func DrawShape(s Shape2D) bool&#123; // rect, ok:= s.(Rectangle) // if ok&#123; // DrawRect(rect) // &#125; // tri, ok:= s.(Triangle) // if ok&#123; // DrawTriangle(tri) // &#125; switch:=sh:=s.(type)&#123; case Rectangle: DrawRect(sh) case Triangle: DrawTriangle(tri) &#125;&#125; Error Interface12345678910type error interface&#123; Error() string&#125;// Handling Errorsf, err := os.Open("/harris/test.txt")if err != nil&#123; fmt.Println(err) return&#125; Why use concurrency Parallel ExecutionTwo programs execute in parallel if they execute at exactly the same time. (At time t, an instruction is being performed for both P! and P2) CPU1, CPU2 Von Neumann Bottlenecka limitation on throughput on personal computerWith the processing becoming faster for processors, the memory transfer rates meet a limitation. To solve that:Cache, Prefetching, Multithreading, DDR SDRAM P = alpha * CFV^2 alpha is percent of time switchingC is capacitanceF is the clock frequencyV is voltage swing Other concurrent tasks can operate while one task is waiting Processes vs. Threads Threads share some context Many threads can exist in one process Goroutines Like a thread in Go Many Goroutines execute within a single OS thread switch the go routines like threads Interleaving Order of execution within a task is unknown Order of execution between concurrent tasks is unknown Interleaving of instructions between tasks is unknown WebThreads are largely independent but not completely independent (some communication between)Web server, one thread per client Image processingblur the pixels1 thread per pixel block (GPU does) some pixel values are shared between the neighbors Create a Goroutine One goroutine is created automatically to execute the main() Other goroutines are created using the go keyword 123a = 1go foo() // 使用go关键词, Main goroutine 不会blocka = 2 when the main goroutine end, all other goroutines will exit Exit goroutinesEarly Exit1234func main()&#123; go fmt.Printf("New routine") fmt.Printf("Main routine")&#125; Only “Main routine” is printed because Main finished before the new goroutine started. Delayed Exit12345func main()&#123; go fmt.Printf("New routine") time.Sleep(100 * time.Millisecond) // Adding a delay to wait is bad because assumptions may be wrong fmt.Printf("Main routine")&#125; Synchronization Using global events whose execution is viewed by all threads, simultaneously GLOBAL EVENT is viewed by all tasks at the same time 123456x = 1x = x+1GLOBAL EVENTif GLOBAL EVENT // x has been updated print x Wait groups Sync package contains functions to synchronize between goroutines sync.WaitGroup forces a goroutine to wait for other goroutines contains an internal counter increment counter for each goroutine to wait for decrement counter when each goroutine completes Waiting goroutine cannot continue until counter is 0 Using waitgroup Add() increments the counterDone() decrements the counterWait() blocks until counter == 0 1234567var wg sync.WaitGroupwg.Add(1)go foo(&amp;wg)wg.Wait() // wait on one thread// 在foo里wg.Done() 123456789101112func foo(wg *sync.WaitGroup)&#123; fmt.Printf("New routine") wg.Done()&#125;func main()&#123; var wg sync.WaitGroup wg.Add(1) go foo (&amp;wg) // 传递引用，免得copy一大堆过去 wg.Wait() fmt.Printf("Main routine")&#125; Channels Transfer data between goroutines Channels are typed Use make() to create a channelc:=make(chan int) send and receive data usign the &lt;- Send data on a channelc&lt;-3 receive data from a channelx := &lt;- c 123456789101112func prod(v1 int, v2 int, c chan int)&#123; c &lt;- v1 * v2&#125;func main()&#123; c := make(chan int) go prod(1, 2, c) go prod(3, 4, c) // In the same channel c a:= &lt;-c b:=&lt;-c fmt.Println(a*b)&#125; cache 是为了弥补高速设备和低速设备的鸿沟而引入的中间层，最终起到加快访问速度的作用。 而 buffer 的主要目的进行流量整形，把突发的大数量较小规模的 I/O 整理成平稳的小数量较大规模的 I/O，以减少响应次数 Unbuffered Channel cannot hold datta in transitSendind blocks until data is receivedReceiving blocks until data is sent 1234567Task 1c &lt;- 3 // no buffer, has to wait for task 2 to receiveOne hour laterTask 2x := &lt;- c // wait task 1 to send So a Wait() should be here Channel Capacity channels can obtain a limited number of objects Capacity is the number of objects it can hold in transit c:=make(chan int, 3) Sending only blocks if buffer is full receiving only blocks if buffer is empty 生产者线程-&gt;有限的缓冲区-&gt;消费者线程 在缓冲区为空时，消费者不能再消费 缓冲区满时，生产者不能再进行生产 Iterate through a channel123for i:= range c&#123; // i is the read value fmt.Println(i)&#125; iterates when sender calls close(c) Receiving from Multiple Goroutines Multiple channels may be used to receive from multiple sources Select Statement May have a choice of which data to use-First come First served use the select statement to wait on the first data from a set of channels 1234567// 只选第一个select&#123; case a = &lt;- c1: fmt.Println(a) case b = &lt;- c2: fmt.Println(b)&#125; 123456select&#123; case a = &lt;- inchan: fmt.Println("Received a") case b = &lt;- outchan: fmt.Println("Send b")&#125; Select with an Abort Channel Producer-consumer12345678for&#123; //infinite for loop keep receiving select&#123; case a &lt;- c: fmt.Println(a) // keep receivinf and processing case &lt;-abort: // abort channel maybe enter quit, 如果有东西到abort channel上了，就会return return &#125;&#125; 12345678select&#123; case a=&lt;-c1: // case b=&lt;-c2: // default: // default case do not block //&#125; Mutual ExclusionTwo goroutines write to a shared variable can interfere with each other. 12345678910111213141516var i int = 0var wg sync.WaitGroupfunc inc()&#123; i = i + 1 wg.Done()&#125;// not corrent!!func main()&#123; wg.Add(2) // create 2 goroutines go inc() go inc() wg.Wait() // wait for the two routines fmt.Println(i) // i should equal 2&#125; seems no problem and i should equal 2?? Granularity of Concurrencyi = i+1 might be three machine instructionsread iincrementwrite i Interleaving machine instructions|Task 1|Task2|i||—|—|—||read i||0|||read i|0||inc||1||write i||1|||inc|1|||write i|1| Correct Sharing Don’t let 2 goroutines write to a shared variable at the same time Mutual Exclusion Sync.Mutex A Mutex ensures mutual exclusion uses a binary semaphore Flag up - shared variable is in use Flag down - shared variable is available Lock() method puts the flag up - shared variale i use Unlock() method puts the flag downWhen Unlock() is called, a Lock() can be proceed 1234567var i int = 0var mut sync.Mutexfunc inc()&#123; mut.Lock() i = i+1 mut.Unlock()&#125; Synchronous InitializationInitialization must happen once and before everything elseSync.Once Has one method, once.Do(f) Function f is executed only one time even if it is ccalled in multiple gotoutines All calls to once.Do() block until the first returns Ensures that init executes first 1234567891011121314151617181920212223var wg sync.WaitGroupfunc main()&#123; wg.Add(2) go dostuff() go dostuff() wg.Wait()&#125;var on sync.Oncefunc setup()&#123; fmt.Pringln("Init")&#125;func dostuff()&#123; on.Do(setup) fmt.Println("hello") wg.Done()&#125;//result// Init// hello// hello Deadlock example1234567891011121314func dostuff(c1 chan int, c2 chan int)&#123; &lt;- c1 c2 &lt;- 1 wg.Done()&#125;func main()&#123; ch1 := make(chan int) ch2 := make(chan int) wg.Add(2) go dostuff(ch1, ch2) go dostuff(ch2, ch1) wg.Wait()&#125; Golang detects when all goroutine are deadlocks, but cannot detect subset of goroutines are deadlocks Dining Philosophers ProblemEach chopstick is a mutexEach philosopher is associated with a goroutine and two chopsticks 123456789101112131415161718192021222324252627282930313233type ChopS struct&#123; sync.Mutex&#125;type Philo struct&#123; leftCS, rightCS *ChopS&#125;func (p Philo) eat()&#123; for&#123; // All people will lock the chopstick on their left side firstly p.leftCS.Lock() p.rightCS.Lock() fmt.Println("eating") p.rightCS.UnLock() p.leftCS.UnLock() &#125;&#125;// initCSticks := make([]*ChopS, 5)for i:=0; i&lt;5; i++&#123; CStick[i] = new(ChopS)&#125;philos := make([]*Philo, 5)for i:=0; i&lt;5; i++&#123; philos[i] = &amp;Philo&#123;CSticks[i], CSticks[(i+1)%5]&#125;&#125;// start eatingfor i:=0; i&lt;5; i++&#123; go philos[i].eat()&#125; 每个人拿最小的Solutionchange to &amp;Philo{CSticks[min(i, (i+1)%5)], CSticks[max(i, (i+1)%5)]}]]></content>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Internet programming]]></title>
    <url>%2Fblog%2F2019%2F10%2F14%2FInternet-programming%2F</url>
    <content type="text"><![CDATA[Internet programming 笔记 note1http: hypertext transfer protocol, the underlying protocol used by the WWW and this protocol defines how messages are formatted and transmitted, and what actions Web servers and browsers should take in response to various commands. https: http over secure session: a temporary and interactive information interchange between two or more communicating devices or between computer and user. Internet vs WWW : Internet is a global network comprised of computers( conceptualized during 1969, APRA), World Wide Web is a collection of web pages following Http that can be accessed via the Internet from any part of the world. Cookie: a small piece of data sent from a website and stored on the user’s computer by the user’s web browser. It can record user’s browsing activity and remember stateful information and arbitrary information that user entered into form fields. JSP: JSP stands for Java Server Pages, which helps developers to create dynamically web pages based on HTML, XML, or other types. Servlets: are Java programs that are already compiled which also creates dynamic web content. HTML: HyperText Markup Language, the authoring language used to create documents on the World Wide Web javascript: make web pages dynamic and interactive by implementing client-side scripts. css: Cascading Style Sheets is a language that describes the style of an HTML document.]]></content>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Screen Design]]></title>
    <url>%2Fblog%2F2019%2F05%2F22%2FScreenDesign%2F</url>
    <content type="text"><![CDATA[A brief introduction of Screen Design Design, 50% instinct, 50% hard work. Gestalt pyschology The whole(unity) is greater than the sum of its parts.(Aristotle) Composition, Symmetry and Balance Pictures need a frame for their composition. Youe must know where is the end of the picture and where begins reality. Composition with perspective not in the middle Symmetry in the composition and in the meaning Golden section Color color palettes Grid Logo from tangram 七巧板 to logotype pictogram 象形符号 Typography Leading captical letter typographie Design Thinking]]></content>
  </entry>
  <entry>
    <title><![CDATA[DSP_SwarmIntelligence]]></title>
    <url>%2Fblog%2F2019%2F05%2F21%2FDSP-SwarmIntelligence%2F</url>
    <content type="text"><![CDATA[Swarm intelligence (SI) is the collective behavior of decentralized, self-organized systems, natural or artificial. The concept is employed in work on artificial intelligence. The expression was introduced by Gerardo Beni and Jing Wang in 1989, in the context of cellular robotic systems How can we implement the coordination among the groups? flask-&gt;waterholr-&gt;on and another predator-&gt;flask split-&gt; knowledge accumulated to concesus penguin-40 together to brook the temperaturehuddle tiny streps awayshift and rotate fro, back to frontnot let the overheat-&gt;breakdown step by step huddle after huddle mayfly flock of fish collide with predator pheromone 信息素]]></content>
  </entry>
  <entry>
    <title><![CDATA[java网络编程]]></title>
    <url>%2Fblog%2F2019%2F05%2F18%2Fjava%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[java网络编程 任务一 TCP实现逆序字符串输出 客户端想要发一行字符行给服务器端然后得到一个逆序的字符行。 SocketClient.java12345678910111213141516171819202122232425262728import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.Socket;import java.net.UnknownHostException;import java.util.Scanner;public class SocketClient &#123; public static void main(String args[]) throws UnknownHostException, IOException &#123; Scanner sc = new Scanner(System.in); Socket socket = new Socket("127.0.0.1", 54321); // get input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); // get output stream PrintStream ps = new PrintStream(socket.getOutputStream()); // write string into server ps.println(sc.nextLine()); // print the reversed string from server System.out.println(br.readLine()); socket.close(); &#125;&#125; SocketServer.java1234567891011121314151617181920212223242526272829303132333435import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.ServerSocket;import java.net.Socket;public class SocketServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket server = new ServerSocket(54321); System.out.println("Server is on, binded to 54321 port"); while (true) &#123; final Socket socket = server.accept(); new Thread() &#123; public void run() &#123; try &#123; // get the input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); PrintStream ps = new PrintStream(socket.getOutputStream()); String line = br.readLine(); line = new StringBuilder(line).reverse().toString(); ps.println(line); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125; 建立Socket连接 客户端Socket指定host和port，服务器Socket使用给定的ServerSocket绑定port即可再调用accept函数，当客户端运行时，会找到指定的host:port，建立和服务器的连接 通信 服务器的输入流就是客户端的输出流，反之亦然。在服务器和客户端都写一个BufferedReader（简称br）用来输入，和一个PrintStream（简称ps）用来输出。我客户端要发一个字符串，就用ps.println输出；服务器要接收就用br.readLine接收（接收就是输入流）；然后我服务器逆序一下字符串用ps输出，客户端用br再接收就是逆序的字符串了。 客户端 服务器 ps输出 -&gt; br接收 reverse字符串 br接收 &lt;- ps输出 有一个误区就是ps的println不是系统的输出，而是把这一行放到服务器和客户端的交流通道里，客户端println输出，服务器就可以用输入的方式读取了，反之亦然 任务二 UDP实现简单计算通信 使用UDP完成简单计算，比如客户端输入3*4，服务端输出12；客户端输入9/3，服务端输出3 UDPclient.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetAddress;import java.net.SocketException;import java.net.UnknownHostException;import java.util.Scanner;import java.util.regex.Matcher;import java.util.regex.Pattern;public class UDPclient &#123; public static int compute(String s) &#123; String pattern = "(\\d*)([\\+\\-\\*\\/])(\\d*)"; Pattern r = Pattern.compile(pattern); Matcher m = r.matcher(s); int consequence = 0; if(m.find())&#123; // necessary! int leftInt = Integer.parseInt(m.group(1)); char operator = m.group(2).charAt(0); int rightInt = Integer.parseInt(m.group(3)); switch(operator) &#123; case '+': consequence = leftInt + rightInt; break; // important! case '-': consequence = leftInt - rightInt; break; case '*': consequence = leftInt * rightInt; break; case '/': consequence = leftInt / rightInt; break; default: &#125; &#125; return consequence; &#125; public static void main(String[] args) &#123; try &#123; Scanner sc = new Scanner(System.in);// byte[] bytes = sc.nextLine().getBytes(); String test =sc.nextLine(); int result1 = compute(test); System.out.println((int) result1); byte[] bytes = (""+result1).getBytes(); DatagramSocket socket = new DatagramSocket(); DatagramPacket packet = new DatagramPacket(bytes, bytes.length); packet.setAddress(InetAddress.getByName("127.0.0.1")); packet.setPort(55555); socket.send(packet); &#125; catch (SocketException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (UnknownHostException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; UDPserver.java1234567891011121314151617181920212223import java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.SocketException;public class UDPserver &#123; public static void main(String[] args) &#123; try &#123; byte[] buf = new byte[1024]; DatagramSocket socket = new DatagramSocket(55555); DatagramPacket packet = new DatagramPacket(buf, buf.length); socket.receive(packet); byte[] data = packet.getData(); System.out.println(new String(data, 0, data.length)); &#125; catch (SocketException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 我在客户端计算了result，因为UDP传递的是数据包，我们把然后把这个result存放在byte数组中，再放到数据包中，用客户端socket的send发送，就可以用服务器端socket的receive接收了。可以看出，我server不用开，client也能发送，就是永远送不到server了，这就是丢包的原理。TCP则是要先建立连接，就保证了数据是能送到位的。其它UDP和TCP的区别： 1、基于连接与无连接； 2、对系统资源的要求（TCP较多，UDP少）； 3、UDP程序结构较简单； 4、流模式与数据报模式 ； 5、TCP保证数据正确性，UDP可能丢包； 6、TCP保证数据顺序，UDP不保证。 参考来源 任务三 多线程实现多客户端通信 建立25个线程，把它建立连接的时间戳、发送信息的时间戳和2秒后断开的时间戳信息，发给服务器显示。 Server.java123456789101112131415161718192021222324252627282930313233import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.ServerSocket;import java.net.Socket;public class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocket serve = new ServerSocket(54322); System.out.println("Server is on and binded to 54322 port"); while (true) &#123; final Socket socket = serve.accept(); new Thread() &#123; public void run() &#123; try &#123; BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); System.out.println(br.readLine()); // receive the timestamp info of // connection and sending infomation System.out.println(br.readLine()); // receive the timestamp info of // disconnection socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125; MutipleClients.java12345678910111213141516171819202122232425262728293031323334353637383940import java.io.IOException;import java.io.PrintStream;import java.net.Socket;import java.sql.Timestamp;public class MutipleClients &#123; public static void main(String[] args) throws IOException &#123; for (int i = 1; i &lt;= 25; i++) &#123; new Thread() &#123; public void run() &#123; try &#123; Socket socket = new Socket("127.0.0.1", 54322); String Stamp1 = new Timestamp(System.currentTimeMillis()).toString(); Thread t = Thread.currentThread(); PrintStream ps = new PrintStream(socket.getOutputStream()); String Stamp2 = new Timestamp(System.currentTimeMillis()).toString(); ps.println("Client " + t.getId() + " connected at " + Stamp1 + " and sent timestamp " + Stamp2); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; String Stamp3 = new Timestamp(System.currentTimeMillis()).toString(); ps.println("Client " + t.getId() + " disconnected at " + Stamp3); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125; 一个服务器与25个客户端进行连接，需要用while(True)使之一直处于accept状态。 服务器要接收两行信息，第一行客户端发来(println)的连接与发送信息时间戳，第二行是过一段时间客户端发来的结束时间戳。 任务四 RMI实现远程方法调用 前面我们看到的都是在客户端处理好数据送给服务器，让服务器进行输出。那有什么办法在服务器上定义一些接口，然后在本地调用呢？ 这就是RMI(remote method invocation)。本地调用方法时实质上是传给服务器该方法的引用，让服务器调用该方法，然后return给本地结果。本地有stub，是远程对象在本地的代理(proxy),类似于RPC系统中的clinet stub。 RMI的实现首先要发现远程对象，那就必须要开启注册表(RTegistry)，什么是注册表？ 拿DNS来类比最为方便，DNS相当于一种注册表。它建立了IP地址和域名的对应，IP就是对远程对象的引用，域名就是远程对象的标识符。格式类似于 rmi://host:port/name。host指明注册表运行的注解，port表明接收调用的端口，name是一个标识该对象的简单名称。下面代码用LocateRegistry.createRegistry方法确定了注册表。再进行bind或rebind操作就可以连接了。 远程接口 IHello.java 1234567// define remote interfaceimport java.rmi.Remote;import java.rmi.RemoteException;public interface IHello extends Remote &#123; public int helloWorld()throws RemoteException;&#125; 实现类 Hello.java 123456789101112131415161718// define the implementation classimport java.io.Serializable;import java.rmi.RemoteException;import java.rmi.server.UnicastRemoteObject;public class Hello extends UnicastRemoteObject implements IHello&#123; private static final long serialVersionUID = 1L; private int index = 0; protected Hello() throws RemoteException&#123; &#125; @Override public int helloWorld() &#123; System.out.println("Hello!"); return ++index; &#125;&#125; 服务器端 HelloServer.java 123456789101112131415import java.rmi.registry.LocateRegistry;import java.rmi.registry.Registry;public class HelloServer &#123; public static void main(String args[]) &#123; try &#123; IHello rhello = new Hello(); Registry registry = LocateRegistry.createRegistry(8888); registry.bind("test",rhello); // in client side rmi://localhost:8888/test System.out.println("Remote Hello Object is bound succesfully!"); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 客户端 HelloClient.java 123456789101112131415import java.rmi.Naming;public class HelloClient &#123; public static void main(String args[]) &#123; try &#123; for(int i=0;i&lt;5;i++) &#123; IHello rhello = (IHello) Naming.lookup("rmi://192.168.31.102:8888/test"); System.out.println(rhello.helloWorld()); &#125; &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SWEII_TEST]]></title>
    <url>%2Fblog%2F2019%2F05%2F17%2FSWEII-TEST%2F</url>
    <content type="text"><![CDATA[4 types of coverage in testing branch coverage&gt;statement coverage because it can examine empty else statement]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DSP_ConsistentModel_Ex]]></title>
    <url>%2Fblog%2F2019%2F05%2F17%2FDSP_ConsistenctModel%2F</url>
    <content type="text"><![CDATA[小练习 P17 VC LA a (1,0,0,0) 1.1 b (2,1,0,0) 2.1 c (3,1,0,0) 3.1 d (4,3,2,0) 6.1 e (5,5,2,2) 7.1 f (6,5,4,2) 8.1 g (7,5,4,2) 9.1 h (0,1,0,0) 1.2 i (1,2,1,0) 3.2 j (1,3,1,0) 4.2 k (1,4,1,2) 5.2 l (1,5,1,2) 6.2 m (4,6,2,4) 9.2 n (7,7,4,4) 10.2 o (1,0,1,0) 2.3 p (1,3,2,0) 5.3 q (3,3,3,0) 6.3 r (3,3,4,0) 7.3 s (1,0,0,1) 2.4 t (1,0,0,2) 3.4 u (4,3,2,3) 7.4 v (4,3,2,4) 8.4 Total/Partial order add process num the timestamp belongs]]></content>
  </entry>
  <entry>
    <title><![CDATA[Equicalence Partitioning Class]]></title>
    <url>%2Fblog%2F2019%2F05%2F02%2FEC%2F</url>
    <content type="text"><![CDATA[在软件工程中，常常遇到测试数据不完全而不能有效地测试出bug的过程，这个时候需要对所有输出进行划分，同时在边界需要格外注意，多测试几组边界值。 empty digits characters 六位id的可写成 id = {num|num = (\d){6,6}}]]></content>
  </entry>
  <entry>
    <title><![CDATA[ds5]]></title>
    <url>%2Fblog%2F2019%2F04%2F26%2Fds5%2F</url>
    <content type="text"><![CDATA[4-26笔记 7 fat client microsoft excel thin client automatioc flight check-in machine 18which is on client and which on server 27localhost：在计算机网络中，localhost（意为“本地主机”，指“这台计算机”）是给回路网络接口（loopback）的一个标准主机名，相对应的IP地址为127.0.0.1（IPv4）和[::1]（IPv6）。127.0.0.1是回送地址，指本地机。127.0.0.1是用来检测网络的自己的IP.就是说任何一台电脑来说,不管是否连接到INTERNET上,127.0.0.1对于自己来说都是自己.就是说,每台电脑都是由4位的256进制数组成的.而192.168.1.102现在是本机，但本机也可以设置成其他ip地址，但127.0.0.1一定是指本机。 JAVA client-server 简单例子Socketclient.java123456789101112131415161718192021222324252627282930import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.Socket;import java.net.UnknownHostException;import java.util.Scanner;public class SocketClient &#123; public static void main(String args[]) throws UnknownHostException, IOException &#123; Scanner sc = new Scanner(System.in); Socket socket = new Socket("127.0.0.1", 54321); // get input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); // get output stream PrintStream ps = new PrintStream(socket.getOutputStream()); // write string into server ps.println(sc.nextLine()); // print the reversed string from server System.out.println(br.readLine()); socket.close(); &#125;&#125;- SocketServer.java1234567891011121314151617181920212223242526272829303132333435import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintStream;import java.net.ServerSocket;import java.net.Socket;public class SocketServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket server = new ServerSocket(54321); System.out.println("Server is on, binded to 54321 port"); while (true) &#123; final Socket socket = server.accept(); new Thread() &#123; public void run() &#123; try &#123; // get the input stream BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); PrintStream ps = new PrintStream(socket.getOutputStream()); String line = br.readLine(); line = new StringBuilder(line).reverse().toString(); ps.println(line); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础]]></title>
    <url>%2Fblog%2F2019%2F04%2F22%2Fjava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JAVA 入门到放弃 Access modifiers(specifiers) in java protected 基类的 protected 成员是包内可见的，并且对子类可见； 若子类与基类不在同一包中，那么在子类中，子类实例可以访问其从基类继承而来的protected方法，而不能访问基类实例的protected方法。 detail overloadeach overloaded method must take a unique list of the argument types override（1）重写方法必须和被重写方法具有相同的参数列表（包括顺序及个数还有类型），返回类型必须和被重写方法的返回类型相同或者是返回类型的子类型。 （2）重写方法的访问控制修饰符不能比被重写方法更严格（比如一个在父类中声明为public的方法重写成一个protected的方法）。 （3）只有实例方法才能被重写，超类中的static和final方法不能被重写。 （4）重写方法不能抛出新的检查异常，或者是抛出比被重写方法声明的检查异常更广泛的检查异常。 （5）注意一种特殊情况：如果超类的方法版本中声明了检查异常，但重写的子类方法中没有声明，这时如果使用多态的方式进行调用，那么编译器认为你调用的是声明了异常的方法。 （6）尽管多态是在编译时确定对象的类型，但在编译时，还是根据父类的方法声明进行程序检查。因此，如果子类中定义的方法，在父类中没有定义，则会出项编译错误。 upcastthe act of converting a subclass reference into a baseclass reference 缺点：使用向上转型时不能调用子类特有的方法了 优点：一个父类有多个子类时，一个子类重写了许多父类的方法，可以声明一个public static函数统一对每个属于父类的子类进行操作，节省代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * @author Spycsh * 2019-04-28 */class Car &#123; private String carDescription = "Car"; public void run() &#123; System.out.println("父类run方法"); &#125; public void speed() &#123; System.out.println("父类speed方法"); &#125; public String getDescription() &#123;return carDescription;&#125;;&#125;class Benz extends Car&#123; public void run() &#123; System.out.println("Benz:run方法"); &#125; public void speed() &#123; System.out.println("Benz:speed方法"); &#125; &#125;class BMW extends Car&#123; public void run() &#123; System.out.println("BMW:run方法"); &#125; public void speed() &#123; System.out.println("BMW:speed方法"); &#125;&#125;class Porsche extends Car&#123; private String carDescription = "Porsche is the best!"; public void run() &#123; System.out.println("Porche:run方法"); &#125; public void speed() &#123; System.out.println("Porche:speed方法"); &#125; public void price() &#123; System.out.println("Porche:price方法"); &#125; public String getDescription() &#123;return carDescription;&#125;;&#125;public class UpcastEX extends Car&#123; /** * @param car * !upcast * without upcast you need to define show method for each car brand * save code amount */ public static void show(Car car) &#123; car.run(); car.speed(); &#125; public static void showAll(Car[] e) &#123; for(Car i:e) &#123; show(i); &#125; &#125; public static void main(String[] args) &#123; Car[] carFleet = &#123; new Benz(), new BMW(), new Porsche() &#125;; showAll(carFleet); Car porsche911 = new Porsche(); //porsche911.price(); // ERROR // !cannot be implemented because of upcasting! // baseclass don`t define price()! System.out.println("test getDescription:"); // show that although upcasting, field are accessed // in subclass, not baseclass. System.out.println(porsche911.getDescription()); &#125;&#125; OUTPUT Benz:run方法 Benz:speed方法 BMW:run方法 BMW:speed方法 Porche:run方法 Porche:speed方法 test getDescription: Porsche is the best! staticstatic修饰方法 静态方法 属于类的方法 即访问它不需要实例对象就能访问 finalstatic, final修饰data static 强调只有一份，final 说明是一个常量，final定义的基本类型(primitive)的值是不可改变的，但是fianl定义的引用对象的值是可以改变的 只申明final，每次new产生不同的对象static, final一起使用时，只有一块存储地址申明static final，每次new产生相同对象 final修饰methods 把方法锁定，确保在继承中使用方法行为不变，并且不会被覆盖其二是效率，如果一个方法指明为final，就是同意编译器将针对该方法的所有调用都转为内嵌调用。 转为内嵌调用的目的是节省开销，因为编译器发现一个final方法调用命令时，会跳过程序代码这种正常方式而执行方法调用机制（将参数压入栈，跳至方法代码处并执行，然后跳回并清理栈中的参数，处理返回值），并且以方法体中的实际代码的副本来替代方法调用。但是如果一个方法很大，程序很膨胀，就会看不到内嵌带来的任何性能的提高。 final修饰类 当某个类的整体定义为final时，表明该类不能被继承，方法不能被覆盖，且final类中的所有方法都隐式指定为是final的，方法声明为final后还可以有效地“关闭”动态绑定。 Containers synchronized 修饰代码块，其他试图访问该对象的线程阻塞123synchronized(this) &#123; // 同步代码块&#125; 对象作为锁123synchronized (account) &#123; // 同步代码块&#125; 没有明确的对象作为锁1234567891011121314class Test implements Runnable&#123; private byte[] lock = new byte[0]; // 特殊的instance变量 public void method() &#123; synchronized(lock) &#123; // todo 同步代码块 &#125; &#125; public void run() &#123; &#125;&#125; 参考资料 消费者-生产者例子 lambda事件监听12345678910// 使用匿名内部类 btn.setOnAction(new EventHandler&lt;ActionEvent&gt;() &#123; @Override public void handle(ActionEvent event) &#123; System.out.println("Hello World!"); &#125; &#125;); // 或者使用 lambda expression btn.setOnAction(event -&gt; System.out.println("Hello World!")); 排序，线程，集合用法参考资料 LinkedList 和 ArrayList 区别LinkedList插入元素（任意位置只要断开链接再与新元素链接即可）很快，但访问中间元素需要从头或从尾开始遍历，很慢。ArrayList插入元素很慢，它需要更新一遍数组，但访问元素只需要给出索引，相对较快。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ds4]]></title>
    <url>%2Fblog%2F2019%2F04%2F12%2Fds4%2F</url>
    <content type="text"><![CDATA[2019-04-12 笔记 File IO operation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import java.util.*;import java.io.*;/** * @author Spycsh ●int countLines(): count line amount of file ●void print(): * print file on command line ●void copy(String filename): copy file * content to the file ‘filename’ ●void delete(): delete the file ●void * printDirectory(): prints the file directory ●List&lt;String&gt; * getOtherFiles(): returns list of other files in same directory as * file Addtionally, create a test class which demonstrates the * functionality of your IOFile class! */public class FileIo &#123; private String fileName; FileIo(String fileName) &#123; this.fileName = fileName; &#125; int countLines() throws FileNotFoundException &#123; int lineNum = 1; File file = new File(this.fileName); FileReader fr = new FileReader(file); char[] a = new char[500]; try &#123; fr.read(a); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for (char c : a) &#123; if (c == '\n') lineNum += 1; &#125; return lineNum; &#125; void print() throws FileNotFoundException &#123; File file = new File(this.fileName); FileReader fr = new FileReader(file); char[] a = new char[500]; try &#123; fr.read(a); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for (char c : a) &#123; System.out.print(c); &#125; &#125; void copy(String filename) throws IOException &#123; // create a new destination file with the filename File copyfile = new File(filename); copyfile.createNewFile(); FileWriter fw = new FileWriter(copyfile); // Read the source file File sourcefile = new File(this.fileName); FileReader fr = new FileReader(sourcefile); char[] a = new char[500]; try &#123; fr.read(a); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for (char c : a) &#123; fw.write(c); &#125; fr.close(); fw.close(); &#125; void delete() &#123; File file = new File(this.fileName); file.delete(); if (file.exists() == true) &#123; System.out.println("delete fail!"); &#125; else &#123; System.out.println("delete success!"); &#125; &#125; void printDirectory() &#123; File file = new File(this.fileName); System.out.println(file.getParent()); &#125; List&lt;String&gt; getOtherFiles() &#123; List&lt;String&gt; anotherFile = new ArrayList&lt;String&gt;(); // first we should get the directory File file = new File(this.fileName); String directoryStr = file.getParent(); File directory = new File(directoryStr); String[] allfile = directory.list(); for (String f : allfile) &#123; // filter given file // We should use equals rather than == // because we just need to filter // by comparing content if (!f.equals(file.getName())) anotherFile.add(f); &#125; return anotherFile; &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SWE]]></title>
    <url>%2Fblog%2F2019%2F04%2F11%2FSWE%2F</url>
    <content type="text"><![CDATA[2019-04-09 笔记 14 Social acceptability: base on culture and region SWING123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import javax.swing.*;import java.awt.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import javax.swing.event.ChangeEvent;import javax.swing.event.ChangeListener;import javafx.scene.control.Button;import javafx.scene.control.CheckBox;import java.util.*;/** * @author Spycsh * */public class FruitHodgepodge &#123; public static void main(String[] args) &#123; JFrame f = new JFrame(); f.setSize(600, 400); f.setTitle("FruitOrder"); JPanel panel = new JPanel(); Set&lt;String&gt; allFruitList = new HashSet&lt;String&gt;(); // display all fruit choosed f.getContentPane().setLayout(new FlowLayout());// f.add("Nor", new Button("Nor")); LinkedList&lt;String&gt; boxList = new LinkedList&lt;String&gt;(); Collections.addAll(boxList, "apple banana kiwi orange melon grape".split(" ")); JCheckBox[] cbs = new JCheckBox[boxList.size()]; for (int i = 0; i &lt; boxList.size(); i++) &#123; JCheckBox cb = cbs[i] = new JCheckBox(boxList.get(i)); cb.addChangeListener(new ChangeListener() &#123; @Override public void stateChanged(ChangeEvent e) &#123; // get the event source( checkbox itself) JCheckBox checkBox = (JCheckBox) e.getSource(); System.out.println(checkBox.getText() + " 是否选中: " + checkBox.isSelected()); if (checkBox.isSelected()) allFruitList.add(checkBox.getText()); else allFruitList.remove(checkBox.getText()); System.out.println(allFruitList); &#125; &#125;); panel.add(cb); &#125; JButton btn = new JButton(); btn.setText("Display the order!"); btn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; JOptionPane testOpt = new JOptionPane(); testOpt.showMessageDialog(new JFrame(), "Your oder:" + "\n" + allFruitList); &#125; &#125;); panel.add(btn); f.setContentPane(panel); // f.setVisible(true); &#125;&#125; JAVAFX123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package application;/** * @author Spycsh * Main window: user can choose from 6 different fruits * After confirming the choice of fruits another window will pop up and tell the user the choice of fruits */import javafx.application.Application;import javafx.stage.Stage;import javafx.scene.Scene;import javafx.scene.layout.BorderPane;import javafx.scene.Group;import javafx.scene.control.CheckBox;import javafx.beans.value.ChangeListener;import javafx.beans.value.ObservableValue;import javafx.scene.layout.GridPane;import javafx.scene.control.Button;import javafx.event.ActionEvent;import javafx.event.EventHandler;import javafx.scene.text.Text;import java.util.*;import java.util.regex.*;public class FruitHodgepodge extends Application &#123; @Override public void start(Stage primaryStage) &#123; try &#123; BorderPane root = new BorderPane(); GridPane gp = new GridPane(); Scene scene = new Scene(gp, 500, 300); LinkedList&lt;String&gt; boxList = new LinkedList&lt;String&gt;(); Collections.addAll(boxList, "apple banana kiwi orange melon grape".split(" ")); CheckBox[] cbs = new CheckBox[boxList.size()]; LinkedList&lt;String&gt; allFruitList = new LinkedList&lt;String&gt;(); // display all fruit choosed // final CheckBox cb; for (int i = 0; i &lt; boxList.size(); i++) &#123;// cbs[i] = boxList.poll(); CheckBox cb = cbs[i] = new CheckBox(boxList.get(i));// final CheckBox cb0 = new CheckBox("checkBox");// final CheckBox cb1 = new CheckBox("aa"); cb.selectedProperty().addListener(new ChangeListener&lt;Boolean&gt;() &#123; public void changed(ObservableValue&lt;? extends Boolean&gt; ov, Boolean old_val, Boolean new_val) &#123;// System.out.println(cb.isSelected());&#125; if (new_val) &#123; allFruitList.offer(cb.getText()); &#125; else &#123; allFruitList.remove(cb.getText()); &#125; System.out.println(allFruitList); &#125; &#125;); gp.add(cb, 0, i); &#125; Button btn = new Button(); btn.setText("Display the order!"); btn.setOnAction(new EventHandler&lt;ActionEvent&gt;() &#123; @Override public void handle(ActionEvent event) &#123; Group root = new Group(); Scene scene = new Scene(root, 300, 250);// Stage stg = new Stage();// System.out.println((String)allFruitList.toString());// Pattern pattern = Pattern.compile("'(\\D+)'");// String i = (String)allFruitList.toString();// Matcher m = pattern.matcher(i);// if (m.find())&#123;// Text text = new Text(100, 100, m.group(1));// root.getChildren().add(text);// &#125;// String[] arr = allFruitList.toString().split("'"); System.out.println(); String orderString = new String(); for (String s : allFruitList) &#123; orderString += s + "\n"; &#125; Text text = new Text(100, 100, "final order:" + "\n" + orderString); root.getChildren().add(text); primaryStage.setScene(scene); primaryStage.show(); &#125; &#125;); gp.add(btn, 10, 0); // place the button scene.getStylesheets().add(getClass().getResource("application.css").toExternalForm()); primaryStage.setScene(scene); primaryStage.show(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; launch(args); &#125;&#125;]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds3h]]></title>
    <url>%2Fblog%2F2019%2F04%2F09%2Fds3h%2F</url>
    <content type="text"><![CDATA[2019-04-09 笔记 P16 What does a ds do? share hardwares, software and data let computers coordinate and synchronize offer users an integrated computing facility not limited by location P17 What is the essetial part? auto scaling &amp; load balance 城市规划例子,when a computer is broken, it will be slower for the system implementation because of the boundary computation which counts on the coordinations one and another computers, so as for synchronization the system have to wait for the slowest computer, with heavier load than others, to process. P18 (b) filters the redundant info and ensure the useful info procured to minimum. (b) will have a higher speed of response. P26 What is Mobility Transparency? eg. Stream serialize deserialize]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eigen-everthing]]></title>
    <url>%2Fblog%2F2019%2F04%2F08%2Feigen-everthing%2F</url>
    <content type="text"><![CDATA[brief introduction of eigenvalue and eigenvector in linear algebra determinant 行列式 eigenvalue特征值/eigenvector特征向量/eigenspace特征空间(all of the eigenvectors that correspond the eigrnvalue) null space nontrival]]></content>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds2]]></title>
    <url>%2Fblog%2F2019%2F04%2F05%2Fds2%2F</url>
    <content type="text"><![CDATA[2019-04-05 笔记 make every attribute private and Use getter and setter to access them Communication of DS synchronous: The sender may block activity until acknowledgement from receiver big-endian大端法 small-endian小端法 ASCII, Unicode external data representation and marshalling alternative method Streamsnote transforming in bytes and characters encoded in unicode, must be 2 bytes not 1 class Employee implements Serializable(In China)-&gt; Seralization-&gt;deserialization-&gt;class Employee(In luebeck) 例子说明：建立一个Student类，把它用Stream的方式serialize再deserialize,从而实现信息的传输。 定义Student类1234567891011121314151617import java.io.*;public class Student implements Serializable &#123; private static final long serialVersionUID = 1L; private int studentNumber; private String degreeCourse; Student(int studentNumber, String degreeCourse) &#123; this.studentNumber = studentNumber; this.degreeCourse = degreeCourse; &#125; @Override public String toString() &#123; return "studentNumber:" + studentNumber + " " + "degreeCourse:" + degreeCourse; &#125;&#125; serialize过程12345678910111213141516import java.io.ObjectOutputStream;import java.io.FileOutputStream;import java.io.IOException;public class TestSerializing &#123; public static void main(String[] args) throws IOException &#123; FileOutputStream fos = new FileOutputStream("test"); ObjectOutputStream oos = new ObjectOutputStream(fos); Student chen = new Student(12, "ITB"); oos.writeObject(chen); oos.close(); fos.close(); &#125;&#125; deserialize过程12345678910111213141516171819import java.io.*;public class TestDeserialize &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; FileInputStream fos = new FileInputStream("test"); ObjectInputStream oos = new ObjectInputStream(fos); Student aStudent = null; try &#123; aStudent = (Student) oos.readObject(); &#125; catch (ClassNotFoundException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(aStudent.toString()); oos.close(); fos.close(); &#125;&#125; 结果test文件中显示乱码，是serialize后的字符流deserialize后通过自己定义的toString打印可以输出原来的信息 疑难 test文件建在项目文件夹而不是src文件夹下 使用ObjectInputStream反序列化的时候，ObjeectInputStream会先读取文件中的serialVersionUID，然后与本地的class文件的serialVersionUID进行对比，如果这两个id不一致，反序列则失败 因此在Student class中定义 1private static final long serialVersionUID = 1L; 即可 参考资料Source]]></content>
      <tags>
        <tag>学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse 高效代码]]></title>
    <url>%2Fblog%2F2019%2F04%2F04%2FEclipse%E7%AE%80%E6%B4%81%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Eclipse use &amp; code convention Eclipse use项目导出压缩包File-&gt;Export-&gt;General-&gt;选择要压缩的类型 修改缩进等格式(CTRL+SHIFT+F)选中代码-&gt;Source-&gt;Format 添加javadoc注释（ALT+SHIFT+J)选中元素-&gt;Source-&gt;Generate Element Comment 改名(ALT+SHIFT+R)选中需要改名的元素-&gt;右键Refactor-&gt;Rename.将会修改文件中所有有这个名字的元素 生成javadoccode conventionjava code convention Javadoc comment Header/Classes Functions Name Package: student Class&amp;Inteface: Student variable&amp;method: inputFileSize constant:MAXWEIGHT Layout/indentation Space]]></content>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Information about application for master degree]]></title>
    <url>%2Fblog%2F2019%2F03%2F19%2FMaster%2F</url>
    <content type="text"><![CDATA[德电160硕士申请 德国信息表 大学名 相关专业名称 地点 绩点要求 托福/GRE要求 申请截止日期 评价 亚琛工业大学 Media Infomatics（多媒体信息） 波恩&amp;亚琛 托福90 3.1 EE,IT,CE 托福90 GREverbal超过%15，quantitive超过%75 Dortmund 大学 机器人自动化 Dortmund 80 3.31 机器人研究方面很强 慕尼黑工业大学 ECE 慕尼黑 3.5+ 88 斯图加特大学 infomation technology 官网 DAAD网址 Stuttgart 70%ofbest-on-scale, e.g.70%/100%; 2.8/4; 2.5/1.0 (for German Marks) 托福80 2.15 EU citizens do not pay tuition, whereas non-EU citizens pay a tuition of 1,500 EUR per semester.（有学费要求） Computer Science 官网 DAAD网址 无 托福80 2.15（winter semester） 6.15(summer semester) Bachelor’s degree with a programme duration of at least six semesters in computer science, software engineering, or in a closely related subject(专业匹配度可能较低)EU citizens do not pay tuition, whereas non-EU citizens pay a tuition of 1,500 EUR per semester.（有学费要求） Saarland University萨尔大学 Saarbrücken Graduate School of Computer Science Saarbrücken 75%以上 推荐GRE，托福95/120 11/15；根据专业 不用学费，强在：马普所，视觉信息但毕业很难，挂科率极高 Saarland University萨尔大学DAAD网址 Visual Computing (MSc) Saarland University萨尔大学 Embedded Systems (MSc) Saarland University萨尔大学 Mathematics and Computer Science (MSc) Saarland University萨尔大学 Computer Science (MSc) KIT EEM,FE,MPD,MSEM,POM,ISEM Karlsruhe 托福90 1/15 30000欧 基本简介学校概览 11所精英大学 理工类3所（慕尼黑工业大学、德累斯顿工业大学、亚琛工业大学），文理类8所（海德堡大学、 柏林自由大学、柏林洪堡大学、慕尼黑大学、图宾根大学、康斯坦茨大学、科隆大学、不莱梅大学） 大学名称对应 TU9 九所德国大学，包括亚琛工业大学RWTH Aachen, 柏林工业大学TU Berlin, 不伦瑞克工业大学TU Braunschweig, 达姆施达特工业大学TU Darmstadt, 德累斯顿工业大学TU Dresden, 莱布尼茨-汉诺威大学Leibniz Universität Hannover, 卡尔斯鲁厄理工学院Karlsruher Institut für Technologie, 慕尼黑工业大学TU München, 斯图加特大学Universität Stuttgart。九所大学都是1900年之前成立的理工高校。 TU9联盟主席Ernst Schmachtenberg博士教授指出，”TU9理工高校联盟就是科研实力的代名词。“ U15 U15大学联盟是德国的大型高校、研究型高校联盟，成立于2012年10月12日。联盟成立宗旨为改善德国科研和教育的架构。占德国高校总数13%的十五所高校，承担了37%的第三方资助、60%的医科资助、43%的博士授予，并获得了43%的莱布尼茨奖。目前联盟主席为海德堡大学校长爱特尔(Bernd Eitel)。联盟成员,柏林自由大学,海德堡大学,柏林洪堡大学,波恩大学,法兰克福大学,弗莱堡大学,哥廷根大学,汉堡大学,科隆大学,莱比锡大学,美因茨大学,慕尼黑大学,明斯特大学,图宾根大学,维尔茨堡大学. 参考DAAD查找路径]]></content>
  </entry>
  <entry>
    <title><![CDATA[少年的诗]]></title>
    <url>%2Fblog%2F2018%2F12%2F13%2F%E5%B0%91%E5%B9%B4%E7%9A%84%E8%AF%97%2F</url>
    <content type="text"><![CDATA[三峡江声流笔底, 六朝帆影落樽前胸中机杼，笔底波澜写一点诗，总是好的 《侠的诗》 “傲指弹云分入酒，青冠流古照秋霜”太平无侠士那就写一点诗放浪侠气 「侠」辞京飘迹楚山茫，谑眼穿尘淡冕光。傲指弹云分入酒，青冠流古照秋霜。 《少年游》 “花有重开日，人无再少年”最好的时光总是少年时那走遍的江河 「入山」山深纵马伫难前，步下飞光百丈渊。雾卷云廊封道尽，雨开峰骨作桥源。悠笛风远惊人迹，长海际回忆陌年。绝处寻松掬水月，春秋一脉本多缘。 「古原雨」故迹青鸦驻，三江入古原。立堤涛水逝，临野聚峰眠。塔外清魂雨，烟间断梦田。萧霜凋旧木，归马闭门前。 「题赛里木湖」深云压海境，微雨落晶珠。几骑寻闲客，风波自在途。 《韵之心》 古有琴谱阳关三叠“劝君更进一杯酒，西出阳关无故人”古有诗歌驻马衔杯“圣代即今多雨露，暂时分手莫踌躇” 「缘深缘浅，留念诸君」何泣春江归晚照？松风水落对槐花。遗朝柳折留寻念，此坊歌倾续梦茶。解带吹心风作客，流光转忆泪分霞。云终不见诸君影，碧海行帆懒问涯。 「岳麓•祭•忆君之风忆水长」 望尽湘江暮，亭间墨客愁。满林兼叶落，独木与谁谋！老雁飞斜镜，青衫立冷丘。出钩疑钓叟，惟是月如舟。 《家国情》 “王师北定中原日”太平年间曾经的荣辱仿佛被渐渐淡化了而那血脉奔腾的黄河长江却依然肃穆 「记南京大屠杀」 寇兵侵戮昔悲史，瑟瑟汗青警自鸣。国父陵前国尽复，雨花台上雨堪惊！三江拾恨祭英骨，亿气同途筑远程。勿任危心流海去，涯间舟载惜天明。]]></content>
  </entry>
</search>
